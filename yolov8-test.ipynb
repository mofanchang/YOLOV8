{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://zihao-download.obs.cn-east-3.myhuaweicloud.com/yolov8/datasets/Triangle_215_Dataset/Triangle_215_Keypoint_YOLO.zip -P datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T11:27:38.969609Z","iopub.execute_input":"2025-03-27T11:27:38.969870Z","iopub.status.idle":"2025-03-27T11:29:01.010990Z","shell.execute_reply.started":"2025-03-27T11:27:38.969848Z","shell.execute_reply":"2025-03-27T11:29:01.010113Z"}},"outputs":[{"name":"stdout","text":"--2025-03-27 11:27:39--  https://zihao-download.obs.cn-east-3.myhuaweicloud.com/yolov8/datasets/Triangle_215_Dataset/Triangle_215_Keypoint_YOLO.zip\nResolving zihao-download.obs.cn-east-3.myhuaweicloud.com (zihao-download.obs.cn-east-3.myhuaweicloud.com)... 121.36.235.163, 121.36.235.162\nConnecting to zihao-download.obs.cn-east-3.myhuaweicloud.com (zihao-download.obs.cn-east-3.myhuaweicloud.com)|121.36.235.163|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 337545608 (322M) [application/zip]\nSaving to: â€˜datasets/Triangle_215_Keypoint_YOLO.zip.6â€™\n\nTriangle_215_Keypoi 100%[===================>] 321.91M  4.91MB/s    in 80s     \n\n2025-03-27 11:29:00 (4.05 MB/s) - â€˜datasets/Triangle_215_Keypoint_YOLO.zip.6â€™ saved [337545608/337545608]\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# # ä¸‹è½½å®Œæ•´å‹ç¼©åŒ…ï¼ˆå¦‚æœå°šæœªä¸‹è½½ï¼‰\n# !wget https://zihao-download.obs.cn-east-3.myhuaweicloud.com/yolov8/datasets/Triangle_215_Dataset/Triangle_215_Keypoint_YOLO.zip -P datasets\n\n# ä»…è§£å‹ labels ç›®å½•åˆ° datasets/\n!unzip datasets/Triangle_215_Keypoint_YOLO.zip \"Triangle_215_Keypoint_YOLO/labels/*\" -d datasets\n\n# åˆ é™¤å‹ç¼©åŒ…ï¼ˆå¯é€‰ï¼‰\n!rm -rf datasets/Triangle_215_Keypoint_YOLO.zip","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!unzip datasets/Triangle_215_Keypoint_YOLO.zip -d datasets >> /dev/null","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -rf datasets/Triangle_215_Keypoint_YOLO.zip","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wget https://zihao-download.obs.cn-east-3.myhuaweicloud.com/yolov8/datasets/Triangle_215_Dataset/Triangle_215.yaml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T13:29:36.672283Z","iopub.execute_input":"2025-03-26T13:29:36.672622Z","iopub.status.idle":"2025-03-26T13:29:40.783112Z","shell.execute_reply.started":"2025-03-26T13:29:36.672585Z","shell.execute_reply":"2025-03-26T13:29:40.782286Z"}},"outputs":[{"name":"stdout","text":"--2025-03-26 13:29:36--  https://zihao-download.obs.cn-east-3.myhuaweicloud.com/yolov8/datasets/Triangle_215_Dataset/Triangle_215.yaml\nResolving zihao-download.obs.cn-east-3.myhuaweicloud.com (zihao-download.obs.cn-east-3.myhuaweicloud.com)... 121.36.235.163, 121.36.235.162\nConnecting to zihao-download.obs.cn-east-3.myhuaweicloud.com (zihao-download.obs.cn-east-3.myhuaweicloud.com)|121.36.235.163|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 483 [text/yaml]\nSaving to: â€˜Triangle_215.yaml.1â€™\n\nTriangle_215.yaml.1 100%[===================>]     483  --.-KB/s    in 0s      \n\n2025-03-26 13:29:40 (137 MB/s) - â€˜Triangle_215.yaml.1â€™ saved [483/483]\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:08:26.184400Z","iopub.execute_input":"2025-03-27T04:08:26.184776Z","iopub.status.idle":"2025-03-27T04:08:31.351869Z","shell.execute_reply.started":"2025-03-27T04:08:26.184745Z","shell.execute_reply":"2025-03-27T04:08:31.350994Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.96-py3-none-any.whl.metadata (35 kB)\nRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.96-py3-none-any.whl (949 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m949.8/949.8 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.96 ultralytics-thop-2.0.14\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"pip install --upgrade ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T12:00:35.978301Z","iopub.execute_input":"2025-03-27T12:00:35.978613Z","iopub.status.idle":"2025-03-27T12:00:41.249922Z","shell.execute_reply.started":"2025-03-27T12:00:35.978586Z","shell.execute_reply":"2025-03-27T12:00:41.248892Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.97-py3-none-any.whl.metadata (35 kB)\nRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.97-py3-none-any.whl (949 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m949.8/949.8 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.97 ultralytics-thop-2.0.14\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# yolov8n-poseæ¨¡å‹ï¼Œè¿ç§»å­¦ä¹ å¾®è°ƒ\n!yolo pose train data=Triangle_215.yaml model=yolov8n-pose.pt pretrained=True project=Triangle_215 name=n_pretrain epochs=50 batch=16 device=0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T13:30:47.465133Z","iopub.execute_input":"2025-03-26T13:30:47.465430Z","iopub.status.idle":"2025-03-26T13:36:38.729072Z","shell.execute_reply.started":"2025-03-26T13:30:47.465402Z","shell.execute_reply":"2025-03-26T13:36:38.728090Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nUltralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=pose, mode=train, model=yolov8n-pose.pt, data=Triangle_215.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=Triangle_215, name=n_pretrain, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=Triangle_215/n_pretrain\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 22.4MB/s]\nOverriding model.yaml kpt_shape=[17, 3] with kpt_shape=[3, 3]\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    823582  ultralytics.nn.modules.head.Pose             [1, [3, 3], [64, 128, 256]]   \nYOLOv8n-pose summary: 144 layers, 3,083,118 parameters, 3,083,102 gradients, 8.4 GFLOPs\n\nTransferred 361/397 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir Triangle_215/n_pretrain', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 108MB/s]\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/labels/train\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/labels/train.cache\nWARNING âš ï¸ No 'flip_idx' array defined in data.yaml, setting augmentation 'fliplr=0.0'\n/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/labels/val... \u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_153602.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_171841.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172124.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172345.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172510.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172619.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172846.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172857.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173044.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173224.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173349.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173410.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173729.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173738.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173752.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173812.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_174128.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_080946.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_080947.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_081012.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_081015.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082240.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082320.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082330.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082423.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/labels/val.cache\nPlotting labels to Triangle_215/n_pretrain/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mTriangle_215/n_pretrain\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       1/50      2.26G       2.16      5.046     0.6916      2.847      2.268   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.732      0.805       0.81      0.611     0.0708      0.256     0.0491    0.00519\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       2/50      2.27G      1.011      4.522     0.6905      1.025      1.252   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.859      0.951      0.956      0.731      0.132      0.183     0.0827     0.0107\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       3/50      2.27G     0.8358      3.804      0.682      0.738      1.141   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.891      0.896      0.943      0.732      0.477      0.463      0.339     0.0407\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       4/50      2.27G     0.9184      3.327     0.6742     0.7858      1.191   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.913      0.878      0.959      0.764       0.75       0.72      0.713      0.177\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       5/50      2.27G     0.8046      2.845     0.6456     0.6611      1.084   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.969      0.902      0.956      0.733      0.943      0.878      0.937      0.346\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       6/50      2.27G     0.7578      2.498     0.6321     0.6224      1.069   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.886      0.948      0.955      0.743      0.812       0.89      0.833      0.331\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       7/50      2.27G     0.8287      2.344     0.6352      0.625      1.108   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.927      0.927      0.968      0.733      0.867      0.854      0.863       0.38\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       8/50      2.27G     0.8587      2.089     0.6183     0.6373      1.117   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.866      0.864      0.921      0.655      0.753      0.744      0.704      0.301\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       9/50      2.27G     0.7954      1.957     0.6045     0.6164      1.095   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.842      0.707      0.857      0.577      0.666      0.585      0.566      0.202\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      10/50      2.27G     0.8537       1.74      0.591     0.6405      1.123   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82       0.87      0.793      0.852       0.59      0.642      0.568      0.431      0.192\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      11/50      2.27G      0.787      1.607      0.596     0.6413      1.092   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.888      0.875       0.93       0.74      0.873      0.923      0.959      0.514\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      12/50      2.27G     0.8225      1.385     0.5736     0.6365      1.113   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.918      0.976       0.98       0.76      0.812      0.894      0.874      0.463\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      13/50      2.27G     0.7624      1.459     0.5539     0.6088      1.086   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.956      0.988      0.992      0.819      0.936      0.963      0.978      0.584\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      14/50      2.27G     0.7368      1.354     0.5469     0.5859      1.046   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82       0.94      0.939      0.981      0.771      0.962      0.924      0.968      0.624\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      15/50      2.27G     0.7178      1.247     0.5614     0.5612      1.063   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.912      0.988      0.981      0.793        0.9      0.976      0.965      0.643\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      16/50      2.27G     0.6961      1.107     0.5536     0.5561      1.041   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.923      0.976      0.974      0.806      0.923      0.976      0.981      0.671\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      17/50      2.27G     0.7144      1.064     0.5534     0.5665      1.048   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.953      0.902      0.981      0.825      0.927      0.878      0.965      0.664\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      18/50      2.27G     0.7103     0.9585     0.5376     0.5311      1.047   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.962      0.976      0.989       0.84      0.946      0.963      0.963      0.777\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      19/50      2.27G     0.7072      1.023     0.5378     0.5491      1.047   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.975      0.932      0.987      0.815      0.975      0.939      0.984      0.789\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      20/50      2.27G      0.638     0.9223     0.5297      0.521      1.017   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.957      0.976      0.983       0.85      0.951      0.948      0.974      0.842\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      21/50      2.27G     0.6608     0.8239     0.5132     0.5088      1.021   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.997      0.951      0.993      0.872      0.997      0.951      0.993      0.832\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      22/50      2.27G     0.7031     0.8047     0.5267     0.5322      1.054   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1          1      0.995      0.872      0.996      0.988      0.993      0.844\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      23/50      2.27G      0.657     0.8398     0.5143     0.4933      1.023   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.979      0.995      0.878          1      0.979      0.995      0.892\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      24/50      2.27G     0.6516     0.7487     0.5125     0.4806      1.012   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.973          1      0.994      0.881      0.962      0.988      0.982       0.87\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      25/50      2.27G     0.5832     0.6508     0.5061     0.4566     0.9857   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.974          1      0.994      0.891      0.974          1      0.994      0.864\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      26/50      2.27G     0.6202     0.7003     0.5097      0.465      1.008   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976      0.995      0.995      0.888      0.984      0.976      0.981      0.887\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      27/50      2.27G     0.6319     0.6809     0.4947      0.486      1.013   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.984          1      0.995      0.897      0.972      0.988      0.986      0.835\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      28/50      2.27G     0.6216     0.7327     0.4789     0.4689     0.9951   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.962          1      0.992      0.895      0.976      0.985      0.985      0.877\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      29/50      2.27G     0.6183     0.6838     0.4775     0.4607     0.9981   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.964      0.985      0.993        0.9      0.964      0.985      0.985      0.901\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      30/50      2.27G     0.5791     0.6414     0.4895     0.4545      0.993   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.992      0.976      0.994      0.912          1      0.959      0.985      0.939\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      31/50      2.27G     0.6099     0.6721     0.4733     0.4561     0.9965   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.984          1      0.995      0.916      0.972      0.988      0.986      0.921\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      32/50      2.27G     0.6129     0.6249     0.4765     0.4595      1.005   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.988      0.996      0.995      0.922      0.988      0.996      0.995      0.947\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      33/50      2.27G     0.5443     0.5435     0.4656     0.4398     0.9656   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976      0.993      0.994      0.909      0.976      0.993      0.994      0.937\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      34/50      2.27G     0.5678     0.5473     0.4576     0.4273     0.9805   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.975          1      0.995      0.923      0.975          1      0.995       0.94\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      35/50      2.27G     0.5308     0.5338     0.4646     0.4156      0.969   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.994      0.988      0.995      0.924      0.994      0.988      0.995      0.952\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      36/50      2.27G     0.5621     0.5744     0.4577     0.4339     0.9865   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976      0.993      0.995      0.914      0.976      0.993      0.995      0.954\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      37/50      2.27G     0.5486     0.4673     0.4342     0.4272     0.9651   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.973      0.988      0.995      0.928      0.973      0.988      0.995      0.968\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      38/50      2.27G     0.5164     0.4325     0.4627     0.4135     0.9717   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.988      0.988      0.995      0.926      0.988      0.988      0.995      0.974\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      39/50      2.27G     0.5285     0.4614     0.4585      0.417     0.9828   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.987      0.988      0.995       0.94      0.987      0.988      0.995      0.969\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      40/50      2.27G       0.51     0.5484     0.4391     0.3968     0.9475   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.988      0.986      0.995      0.939      0.988      0.986      0.995      0.961\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      41/50      2.27G     0.3513     0.3616     0.2466     0.3351     0.8596   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.982      0.988      0.994      0.928      0.982      0.988      0.994      0.965\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      42/50      2.27G     0.3509     0.3007     0.2486     0.2884      0.862   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.974      0.994      0.924          1      0.974      0.994       0.97\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      43/50      2.27G     0.3393     0.2835     0.2515     0.2719     0.8657   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.971      0.993      0.939          1      0.971      0.994      0.957\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      44/50      2.27G     0.3432     0.3154     0.2574     0.2683      0.869   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.971      0.988       0.99      0.934      0.973      0.988      0.994      0.963\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      45/50      2.27G     0.3415     0.2484     0.2369     0.2564     0.8689   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.975      0.988      0.987      0.941      0.981      0.988      0.994      0.965\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      46/50      2.27G     0.3209     0.2919     0.2507     0.2524     0.8644   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.972      0.988      0.942          1      0.972      0.994       0.97\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      47/50      2.27G     0.3138     0.2784     0.2401      0.242     0.8587   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.982      0.995      0.942          1      0.982      0.995       0.97\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      48/50      2.27G     0.2924     0.2415     0.2437     0.2287     0.8554   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.994      0.988      0.995      0.952      0.994      0.988      0.995      0.972\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      49/50      2.27G     0.2896     0.2146       0.23     0.2252       0.82   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.985      0.995      0.951          1      0.985      0.995      0.979\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      50/50      2.27G     0.2853     0.2295     0.2257     0.2237     0.8273   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.985      0.988      0.994      0.951      0.985      0.988      0.994      0.978\n\n50 epochs completed in 0.082 hours.\nOptimizer stripped from Triangle_215/n_pretrain/weights/last.pt, 6.4MB\nOptimizer stripped from Triangle_215/n_pretrain/weights/best.pt, 6.4MB\n\nValidating Triangle_215/n_pretrain/weights/best.pt...\nUltralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLOv8n-pose summary (fused): 81 layers, 3,077,822 parameters, 0 gradients, 8.3 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.985      0.995      0.951          1      0.985      0.995      0.977\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nSpeed: 0.1ms preprocess, 2.0ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1mTriangle_215/n_pretrain\u001b[0m\nğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# yolov8s-poseæ¨¡å‹ï¼Œè¿ç§»å­¦ä¹ å¾®è°ƒ\n!yolo pose train data=Triangle_215.yaml model=yolov8s-pose.pt pretrained=True project=Triangle_215 name=s_pretrain epochs=50 batch=16 device=0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T13:44:07.877792Z","iopub.execute_input":"2025-03-26T13:44:07.878141Z","iopub.status.idle":"2025-03-26T13:50:01.710693Z","shell.execute_reply.started":"2025-03-26T13:44:07.878111Z","shell.execute_reply":"2025-03-26T13:50:01.709853Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s-pose.pt to 'yolov8s-pose.pt'...\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22.4M/22.4M [00:00<00:00, 72.6MB/s]\nUltralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=pose, mode=train, model=yolov8s-pose.pt, data=Triangle_215.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=Triangle_215, name=s_pretrain, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=Triangle_215/s_pretrain\nOverriding model.yaml kpt_shape=[17, 3] with kpt_shape=[3, 3]\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2403406  ultralytics.nn.modules.head.Pose             [1, [3, 3], [128, 256, 512]]  \nYOLOv8s-pose summary: 144 layers, 11,422,958 parameters, 11,422,942 gradients, 29.6 GFLOPs\n\nTransferred 361/397 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir Triangle_215/s_pretrain', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/labels/train\u001b[0m\nWARNING âš ï¸ No 'flip_idx' array defined in data.yaml, setting augmentation 'fliplr=0.0'\n/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/labels/val.cac\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_153602.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_171841.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172124.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172345.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172510.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172619.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172846.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172857.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173044.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173224.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173349.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173410.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173729.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173738.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173752.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173812.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_174128.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_080946.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_080947.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_081012.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_081015.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082240.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082320.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082330.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082423.jpg: corrupt JPEG restored and saved\nPlotting labels to Triangle_215/s_pretrain/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mTriangle_215/s_pretrain\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       1/50      4.38G      2.007      4.887     0.6932      2.935       2.18   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.809      0.915      0.886       0.69      0.102      0.268     0.0797    0.00856\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       2/50      4.39G     0.9032      3.854     0.6773     0.8023      1.191   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.724      0.902      0.851      0.669      0.287      0.378      0.194      0.025\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       3/50       4.4G     0.8346      2.879     0.6845     0.7184      1.147   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.831       0.78      0.823      0.547      0.684      0.829      0.714      0.205\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       4/50       4.4G      0.895      2.369     0.6617     0.7782      1.167   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.573      0.768      0.718      0.464      0.536       0.72      0.616      0.263\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       5/50      4.41G     0.7974      1.885     0.6293     0.6744      1.083   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.368      0.817      0.477      0.258      0.308      0.659      0.405      0.174\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       6/50      4.41G     0.7671      1.663     0.6134     0.6691      1.077   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.685      0.805      0.825      0.494       0.59      0.772      0.687      0.364\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       7/50      4.41G     0.8072      1.568      0.595     0.6677      1.104   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.406      0.585      0.474      0.292      0.284      0.576      0.285     0.0887\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       8/50      4.41G     0.9155      1.465     0.5735     0.7191      1.162   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82       0.51      0.537      0.543      0.355       0.58      0.683      0.668      0.346\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       9/50      4.41G      0.844       1.44     0.5646     0.6878      1.121   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.751      0.659      0.752      0.539      0.718      0.646      0.742      0.402\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      10/50      4.41G     0.8993      1.285     0.5506     0.6989       1.14   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.344      0.707      0.307      0.199      0.348      0.695      0.325      0.195\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      11/50      4.41G      0.776      1.112     0.5418     0.6516      1.088   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.614      0.768      0.779      0.577      0.513      0.646      0.545      0.234\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      12/50      4.41G     0.8152      1.045     0.5266     0.6737      1.123   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.609      0.798      0.756      0.543       0.61      0.801      0.744      0.353\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      13/50      4.41G     0.7897       1.05       0.51     0.6344        1.1   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.761       0.89      0.885      0.612      0.668      0.805      0.684      0.334\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      14/50      4.41G     0.7801       1.04     0.4974     0.6372      1.072   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.906      0.939      0.954      0.761      0.859      0.889      0.872      0.589\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      15/50      4.41G     0.7528     0.9093     0.5033     0.5905      1.078   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.938      0.919      0.973      0.795      0.913      0.897       0.95      0.775\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      16/50      4.41G     0.7122     0.8456     0.4842     0.5657      1.056   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.951      0.955      0.981      0.819      0.914      0.915       0.92      0.761\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      17/50      4.41G     0.7205     0.8363     0.4803     0.5718      1.055   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82       0.88      0.793      0.915      0.746      0.872      0.854      0.934      0.748\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      18/50      4.41G     0.6978     0.7368     0.4719     0.5415      1.046   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82       0.93      0.951      0.965      0.829       0.93      0.951      0.955      0.837\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      19/50      4.41G     0.6777     0.7955     0.4786     0.5576      1.037   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.988      0.972      0.991      0.847          1      0.984      0.995      0.897\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      20/50      4.41G     0.6351      0.702     0.4569     0.5306      1.026   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976      0.993      0.995      0.881      0.976      0.989      0.995      0.857\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      21/50      4.41G     0.6571      0.647     0.4402     0.5054      1.026   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.985          1      0.995      0.881      0.985          1      0.995      0.907\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      22/50      4.41G     0.7112     0.6717     0.4448     0.5534       1.06   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976      0.976      0.984      0.881      0.986      0.951      0.963      0.871\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      23/50      4.41G     0.6794     0.6982     0.4369     0.5201      1.038   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.985      0.963      0.982      0.851      0.997      0.976      0.985      0.883\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      24/50      4.41G     0.6234     0.6246     0.4156     0.4876      1.001   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.975      0.963      0.987      0.861      0.975      0.963      0.994      0.916\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      25/50      4.41G     0.6048     0.5069     0.4195     0.4703     0.9917   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.975      0.963      0.983      0.869      0.979      0.951      0.984      0.889\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      26/50      4.41G     0.6425     0.5476     0.4251     0.4959      1.021   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.964      0.981       0.99      0.891      0.964      0.981       0.99      0.929\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      27/50      4.41G      0.659     0.5553       0.42     0.5092       1.03   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.973          1      0.994      0.887      0.973          1      0.994      0.918\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      28/50      4.41G     0.6013     0.5698     0.3988     0.4769     0.9972   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.987      0.976       0.99      0.897      0.975      0.963      0.974      0.937\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      29/50      4.41G     0.6096      0.526     0.3948     0.4813     0.9968   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.997      0.988      0.995       0.91      0.988      0.987      0.986      0.948\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      30/50      4.41G     0.5845      0.491     0.4041      0.462     0.9929   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.999      0.988      0.994      0.911      0.986      0.976       0.98      0.943\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      31/50      4.41G     0.5868      0.493     0.3888     0.4657     0.9975   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.999      0.976      0.994      0.915      0.999      0.976      0.988      0.916\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      32/50      4.41G      0.592     0.4961     0.3942     0.4594     0.9957   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.984      0.988      0.994      0.932      0.997      0.963      0.988      0.944\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      33/50      4.41G     0.5352     0.3912     0.3881     0.4379     0.9674   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.999          1      0.995      0.937          1      0.985      0.995      0.953\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      34/50      4.41G      0.558     0.4186     0.3673      0.437     0.9733   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.998      0.995      0.929          1      0.998      0.995      0.978\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      35/50      4.41G      0.527     0.4606     0.3845     0.4235     0.9746   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.998          1      0.995      0.938      0.998      0.988      0.989      0.974\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      36/50      4.41G     0.5517     0.4503     0.3773     0.4255      0.988   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.998          1      0.995       0.94      0.998          1      0.995      0.962\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      37/50      4.41G     0.5243     0.3819     0.3453     0.4211     0.9546   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.986          1      0.995      0.934      0.986          1      0.995       0.97\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      38/50      4.41G     0.5183     0.3209     0.3727      0.417     0.9758   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.999          1      0.995      0.932      0.974      0.976      0.981       0.96\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      39/50      4.41G     0.5215      0.359     0.3669     0.4102     0.9792   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.998      0.995      0.936      0.976      0.974       0.98      0.965\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      40/50      4.41G     0.4991     0.4036     0.3498     0.4063     0.9541   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.998          1      0.995      0.947      0.986      0.963      0.988      0.964\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      41/50      4.41G     0.3475     0.2368      0.183     0.3242     0.8716   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.998          1      0.995      0.948      0.973      0.976      0.987      0.959\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      42/50      4.41G     0.3421     0.2018      0.179     0.2837     0.8585   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.999          1      0.995      0.945      0.983      0.976      0.979      0.964\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      43/50      4.41G     0.3303     0.2046     0.1901     0.2736     0.8659   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.987          1      0.995      0.937      0.984      0.976      0.979      0.962\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      44/50      4.41G     0.3398     0.2164     0.1856     0.2696     0.8724   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.999          1      0.995      0.947      0.988      0.976      0.979      0.966\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      45/50      4.41G     0.3198     0.1706     0.1659     0.2498     0.8645   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.999          1      0.995      0.946          1      0.987      0.988      0.972\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      46/50      4.41G     0.3094     0.2021     0.1687     0.2449     0.8647   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.999          1      0.995      0.942          1      0.987      0.988      0.972\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      47/50      4.41G      0.299     0.1605     0.1682     0.2408     0.8544   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1          1      0.995      0.955      0.999      0.988      0.989      0.974\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      48/50      4.41G     0.2862     0.1511     0.1826     0.2296     0.8524   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1          1      0.995      0.952      0.999      0.988       0.99      0.977\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      49/50      4.41G     0.2746     0.1208     0.1528     0.2223     0.8141   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1          1      0.995      0.954      0.999      0.988       0.99      0.979\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      50/50      4.41G     0.2773       0.14     0.1464     0.2235      0.827   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1          1      0.995      0.954      0.999      0.988       0.99      0.979\n\n50 epochs completed in 0.088 hours.\nOptimizer stripped from Triangle_215/s_pretrain/weights/last.pt, 23.1MB\nOptimizer stripped from Triangle_215/s_pretrain/weights/best.pt, 23.1MB\n\nValidating Triangle_215/s_pretrain/weights/best.pt...\nUltralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLOv8s-pose summary (fused): 81 layers, 11,412,750 parameters, 0 gradients, 29.4 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1          1      0.995      0.954      0.999      0.988       0.99      0.979\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nSpeed: 0.1ms preprocess, 4.0ms inference, 0.0ms loss, 1.1ms postprocess per image\nResults saved to \u001b[1mTriangle_215/s_pretrain\u001b[0m\nğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# yolov8m-poseæ¨¡å‹ï¼Œè¿ç§»å­¦ä¹ å¾®è°ƒ\n!yolo pose train data=Triangle_215.yaml model=yolov8m-pose.pt pretrained=True project=Triangle_215 name=m_pretrain epochs=50 batch=16 device=0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T14:09:07.594522Z","iopub.execute_input":"2025-03-26T14:09:07.594924Z","iopub.status.idle":"2025-03-26T14:17:30.209975Z","shell.execute_reply.started":"2025-03-26T14:09:07.594888Z","shell.execute_reply":"2025-03-26T14:17:30.209085Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m-pose.pt to 'yolov8m-pose.pt'...\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50.8M/50.8M [00:00<00:00, 113MB/s]\nUltralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=pose, mode=train, model=yolov8m-pose.pt, data=Triangle_215.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=Triangle_215, name=m_pretrain, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=Triangle_215/m_pretrain\nOverriding model.yaml kpt_shape=[17, 3] with kpt_shape=[3, 3]\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n 22        [15, 18, 21]  1   4338046  ultralytics.nn.modules.head.Pose             [1, [3, 3], [192, 384, 576]]  \nYOLOv8m-pose summary: 184 layers, 26,418,670 parameters, 26,418,654 gradients, 81.2 GFLOPs\n\nTransferred 481/517 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir Triangle_215/m_pretrain', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/labels/train\u001b[0m\nWARNING âš ï¸ No 'flip_idx' array defined in data.yaml, setting augmentation 'fliplr=0.0'\n/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/labels/val.cac\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_153602.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_171841.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172124.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172345.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172510.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172619.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172846.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172857.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173044.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173224.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173349.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173410.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173729.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173738.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173752.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173812.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_174128.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_080946.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_080947.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_081012.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_081015.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082240.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082320.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082330.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082423.jpg: corrupt JPEG restored and saved\nPlotting labels to Triangle_215/m_pretrain/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 83 weight(decay=0.0), 93 weight(decay=0.0005), 92 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mTriangle_215/m_pretrain\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       1/50      7.89G      2.247       4.96     0.7136      3.351      2.573   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.703      0.854      0.813       0.51      0.148      0.256     0.0666    0.00733\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       2/50      7.92G     0.9055      3.872      0.672     0.8975      1.289   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.559       0.78      0.686       0.43      0.437       0.61      0.381     0.0688\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       3/50      7.93G     0.8558      2.659     0.6118     0.8126      1.238   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.343      0.293      0.202     0.0701      0.227      0.451      0.236     0.0524\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       4/50      7.93G     0.9293      2.311     0.5722     0.9196      1.299   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82     0.0265      0.463     0.0174    0.00742     0.0309      0.561     0.0269    0.00795\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       5/50      7.93G     0.8288      1.953     0.5359     0.7956      1.193   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.104      0.549     0.0746     0.0295     0.0906      0.463     0.0695     0.0268\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       6/50      7.93G     0.8424      1.746     0.5338     0.7532      1.194   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82     0.0552      0.598     0.0469     0.0213     0.0534      0.598     0.0433     0.0121\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       7/50      7.93G     0.9235      1.891     0.5318     0.8492      1.292   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.386      0.634      0.491       0.27      0.297      0.549      0.291      0.114\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       8/50      7.93G       1.02      1.786     0.5021     0.8879      1.336   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.274        0.5      0.211      0.104      0.251      0.537      0.189     0.0752\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       9/50      7.93G     0.9143      1.619     0.4887     0.8429       1.26   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.438      0.341      0.315      0.118      0.359       0.28      0.284      0.104\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      10/50      7.93G      0.986      1.458     0.4736     0.8528      1.296   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.429      0.677      0.509       0.25      0.367      0.579      0.407      0.185\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      11/50      7.93G     0.8569       1.39     0.4781     0.7725       1.23   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.187      0.561      0.159     0.0748      0.171      0.541       0.14     0.0525\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      12/50      7.93G     0.8698      1.276     0.4607     0.7834       1.24   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.631       0.72      0.693       0.45       0.55      0.646      0.557      0.276\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      13/50      7.93G     0.8342      1.423     0.4546      0.731      1.228   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.776      0.677      0.765      0.477      0.655      0.512      0.558      0.275\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      14/50      7.93G     0.8311      1.292     0.4333      0.737       1.21   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.738      0.805      0.739      0.493      0.645      0.665      0.594      0.267\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      15/50      7.93G     0.7955       1.11     0.4423     0.7092      1.194   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.784      0.732      0.803       0.57      0.793      0.732      0.824       0.53\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      16/50      7.93G     0.7653     0.9895     0.4102     0.6855       1.16   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.946      0.852      0.954      0.716      0.858      0.812      0.861      0.574\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      17/50      7.93G     0.7836      1.037     0.4284     0.6925       1.17   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.946      0.862      0.962      0.793       0.92      0.837      0.916      0.719\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      18/50      7.93G     0.7398     0.8888      0.409     0.6379      1.145   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.918      0.902      0.964      0.807       0.93      0.915      0.984      0.757\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      19/50      7.93G     0.7056     0.9607     0.4132     0.6298      1.122   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.916       0.93      0.974      0.824      0.955      0.915      0.957      0.802\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      20/50      7.93G     0.6709     0.9591     0.3924     0.6335       1.13   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.952      0.958      0.979      0.846      0.951      0.956      0.976      0.806\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      21/50      7.93G     0.6922     0.7857     0.3638      0.612      1.123   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82       0.94      0.976       0.98      0.863      0.942      0.987      0.989      0.816\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      22/50      7.93G     0.7238     0.8203     0.3715     0.6448       1.15   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.997      0.963      0.988      0.848      0.997      0.963      0.981      0.797\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      23/50      7.93G     0.6969     0.8341     0.3738     0.6011      1.125   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.991      0.963      0.994      0.877      0.989      0.976      0.994      0.864\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      24/50      7.93G     0.6607     0.7313      0.353     0.5666      1.087   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.969      0.976      0.993      0.879      0.969      0.976      0.993      0.887\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      25/50      7.93G     0.6181       0.65     0.3505     0.5536      1.079   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.981      0.963      0.993      0.904      0.953      0.981      0.988      0.907\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      26/50      7.93G     0.6418     0.6663     0.3453     0.5658      1.096   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.981      0.976      0.994      0.897       0.98      0.976      0.994      0.901\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      27/50      7.93G     0.6557     0.6742     0.3485      0.566      1.085   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976      0.993      0.995      0.886      0.976      0.993      0.995      0.886\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      28/50      7.93G     0.6163     0.7239     0.3342      0.533      1.065   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.985      0.988      0.993      0.907      0.997          1      0.995      0.837\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      29/50      7.93G     0.6105       0.67     0.3178     0.5445      1.066   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.982      0.976      0.989      0.911      0.994      0.988      0.995      0.896\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      30/50      7.93G        0.6     0.6276     0.3317       0.55      1.068   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.984          1      0.995      0.918      0.984          1      0.995      0.931\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      31/50      7.93G     0.6003     0.6321     0.3102     0.5359       1.07   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1       0.96      0.994      0.919          1       0.96      0.994      0.954\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      32/50      7.93G     0.5954      0.557     0.3145     0.5411      1.075   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976      0.987      0.994      0.911      0.976      0.987      0.994      0.945\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      33/50      7.93G       0.56     0.5009     0.3019     0.5126      1.051   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.949      0.963      0.991      0.893      0.949      0.963      0.991      0.926\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      34/50      7.93G     0.5443     0.4892     0.2797     0.4873      1.029   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.973      0.988      0.994       0.92      0.973      0.988      0.994      0.942\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      35/50      7.93G     0.5429     0.4925     0.3166     0.4961      1.043   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.997      0.995       0.92          1      0.997      0.995      0.966\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      36/50      7.93G      0.555     0.5038     0.2914     0.4878      1.053   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.983          1      0.995      0.936      0.983          1      0.995      0.966\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      37/50      7.93G     0.5413     0.4373     0.2611     0.4725      1.024   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.953          1      0.993      0.934      0.973          1      0.994      0.968\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      38/50      7.93G     0.5154     0.3531     0.2759     0.4752      1.044   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.952          1      0.992      0.941      0.952          1      0.992      0.959\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      39/50      7.93G     0.5362     0.4078     0.2646     0.4704      1.048   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.987      0.988      0.994       0.93      0.987      0.988      0.994      0.972\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      40/50      7.93G       0.51     0.4684     0.2713     0.4623      1.015   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.988       0.99      0.995      0.942      0.988       0.99      0.995      0.971\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      41/50      7.93G     0.3521     0.2649     0.1889     0.4171     0.8988   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.988      0.998      0.995       0.94      0.988      0.998      0.995      0.968\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      42/50      7.93G     0.3341     0.2248      0.167     0.3297     0.8754   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.999          1      0.995      0.943      0.999          1      0.995      0.959\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      43/50      7.93G     0.3172     0.2133     0.1782     0.3023     0.8835   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.971      0.994      0.949          1      0.971      0.995      0.969\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      44/50      7.93G     0.3333     0.2445     0.1615     0.3023     0.8945   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.988      0.982      0.994      0.949      0.985          1      0.995       0.97\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      45/50      7.93G     0.3179     0.1824     0.1541     0.2909     0.8831   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.986      0.988      0.993      0.954      0.986      0.988      0.994      0.976\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      46/50      7.93G     0.3007     0.1971     0.1578     0.2837     0.8806   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.963          1      0.994      0.953      0.963          1      0.994      0.981\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      47/50      7.93G      0.289     0.1781     0.1485     0.2685     0.8704   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.974      0.995      0.961          1      0.974      0.995      0.985\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      48/50      7.93G     0.2768     0.1716     0.1569     0.2642     0.8638   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.988      0.997      0.995      0.966      0.988      0.997      0.995      0.981\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      49/50      7.93G     0.2613     0.1341     0.1308     0.2498     0.8311   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.987          1      0.995      0.971      0.987          1      0.995      0.983\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      50/50      7.93G     0.2572     0.1751     0.1358     0.2546     0.8442   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.983          1      0.995      0.969      0.983          1      0.995      0.983\n\n50 epochs completed in 0.129 hours.\nOptimizer stripped from Triangle_215/m_pretrain/weights/last.pt, 53.2MB\nOptimizer stripped from Triangle_215/m_pretrain/weights/best.pt, 53.2MB\n\nValidating Triangle_215/m_pretrain/weights/best.pt...\nUltralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLOv8m-pose summary (fused): 101 layers, 26,401,822 parameters, 0 gradients, 80.8 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.987          1      0.995      0.971      0.987          1      0.995      0.983\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nSpeed: 0.2ms preprocess, 10.3ms inference, 0.0ms loss, 1.4ms postprocess per image\nResults saved to \u001b[1mTriangle_215/m_pretrain\u001b[0m\nğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# yolov8l-poseæ¨¡å‹ï¼Œè¿ç§»å­¦ä¹ å¾®è°ƒ\n!yolo pose train data=Triangle_215.yaml model=yolov8l-pose.pt pretrained=True project=Triangle_215 name=l_pretrain epochs=50 batch=4 device=0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T14:33:47.558819Z","iopub.execute_input":"2025-03-26T14:33:47.559157Z","iopub.status.idle":"2025-03-26T14:48:45.837141Z","shell.execute_reply.started":"2025-03-26T14:33:47.559128Z","shell.execute_reply":"2025-03-26T14:48:45.836103Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l-pose.pt to 'yolov8l-pose.pt'...\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85.3M/85.3M [00:00<00:00, 91.7MB/s]\nUltralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=pose, mode=train, model=yolov8l-pose.pt, data=Triangle_215.yaml, epochs=50, time=None, patience=100, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=Triangle_215, name=l_pretrain, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=Triangle_215/l_pretrain\nOverriding model.yaml kpt_shape=[17, 3] with kpt_shape=[3, 3]\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   6433966  ultralytics.nn.modules.head.Pose             [1, [3, 3], [256, 512, 512]]  \nYOLOv8l-pose summary: 224 layers, 44,481,006 parameters, 44,480,990 gradients, 169.1 GFLOPs\n\nTransferred 631/637 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir Triangle_215/l_pretrain', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/labels/train\u001b[0m\nWARNING âš ï¸ No 'flip_idx' array defined in data.yaml, setting augmentation 'fliplr=0.0'\n/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/labels/val.cac\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_153602.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_171841.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172124.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172345.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172510.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172619.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172846.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172857.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173044.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173224.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173349.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173410.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173729.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173738.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173752.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173812.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_174128.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_080946.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_080947.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_081012.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_081015.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082240.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082320.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082330.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082423.jpg: corrupt JPEG restored and saved\nPlotting labels to Triangle_215/l_pretrain/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 103 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mTriangle_215/l_pretrain\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       1/50      3.53G      1.429      4.526     0.7136      1.911      1.767   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.176      0.195     0.0834     0.0327      0.233      0.256       0.12     0.0242\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       2/50      3.53G      1.408      3.465     0.6128      1.686      1.635   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82     0.0145      0.463    0.00955    0.00266    0.00483      0.159    0.00301   0.000663\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       3/50      3.53G       1.57      3.441     0.6107      1.706      1.858   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82     0.0155      0.256    0.00784    0.00184    0.00648      0.195    0.00391   0.000816\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       4/50      3.53G      1.769        3.6     0.5825      1.781      1.894   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82     0.0907       0.28     0.0927     0.0204      0.205      0.256      0.175     0.0308\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       5/50      3.53G      1.373      2.983     0.5548      1.509      1.657   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.258      0.378      0.223      0.106      0.307      0.481      0.281     0.0849\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       6/50      3.53G      1.372      2.892      0.577       1.35      1.667   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.435      0.488      0.477      0.233      0.262      0.305       0.17     0.0493\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       7/50      3.53G      1.344      2.808     0.5759       1.32       1.65   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82       0.47        0.5      0.501       0.29      0.468      0.439      0.429       0.17\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       8/50      3.53G      1.265      2.362     0.5413      1.197      1.591   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.677      0.716      0.677      0.416      0.439      0.463      0.374      0.171\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       9/50      3.53G      1.182      2.255     0.5325      1.146      1.504   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.806      0.671      0.775      0.538      0.701      0.515      0.577      0.241\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      10/50      3.53G      1.184      2.109       0.54      1.193      1.518   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.828      0.765      0.853      0.622      0.788      0.681      0.761      0.424\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      11/50      3.53G      1.069      1.913     0.5143      1.025      1.445   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.814      0.641      0.792      0.628      0.861      0.671        0.8      0.462\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      12/50      3.53G      1.074      1.926     0.5282      1.082       1.45   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.918      0.822      0.932      0.714      0.854      0.782      0.852       0.46\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      13/50      3.53G      1.039      1.896     0.5061      1.033      1.418   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.921      0.915      0.954      0.764      0.855      0.854      0.867      0.481\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      14/50      3.53G     0.9842      1.586     0.4654     0.9778      1.357   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82        0.8      0.827      0.877       0.69      0.801      0.834      0.859      0.525\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      15/50      3.53G      1.028       1.56      0.504      1.023      1.416   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.908      0.915      0.953      0.756      0.925      0.878      0.952      0.656\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      16/50      3.53G     0.9145       1.48     0.4866     0.9083      1.311   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.973       0.89      0.976      0.766      0.941       0.89      0.969      0.667\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      17/50      3.53G     0.9659       1.47     0.4594     0.9295      1.325   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.952       0.97      0.988      0.841       0.94      0.958      0.971      0.651\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      18/50      3.53G      0.877       1.42     0.4656     0.8414      1.281   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.948      0.889       0.97      0.813      0.961      0.895      0.969      0.676\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      19/50      3.53G     0.8649       1.32     0.4768     0.8556       1.29   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.982      0.939      0.984      0.836      0.982      0.939      0.984      0.696\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      20/50      3.53G      0.822      1.233     0.4648     0.8274      1.258   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.952      0.963      0.981      0.845      0.917      0.943      0.967      0.697\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      21/50      3.53G     0.8081       1.18     0.4419     0.8032      1.225   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.938      0.963      0.979       0.83      0.889      0.878      0.923      0.707\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      22/50      3.53G      0.862      1.222     0.4585     0.8415      1.276   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.962      0.921      0.981      0.849      0.962      0.921      0.975      0.765\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      23/50      3.53G     0.8592      1.229     0.4494     0.8339      1.269   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.975      0.927       0.99      0.868      0.962      0.915      0.973      0.766\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      24/50      3.53G     0.7645      1.168     0.4457     0.7393      1.211   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.953      0.986      0.991      0.874      0.949      0.963      0.972      0.809\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      25/50      3.53G     0.7405      1.053     0.4116     0.7405      1.212   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.966      0.993      0.872      0.996      0.951      0.991      0.785\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      26/50      3.53G     0.7259      1.085     0.4108     0.7174      1.166   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.969      0.951      0.989      0.867      0.972      0.951      0.988      0.764\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      27/50      3.53G     0.7644     0.9284     0.4205     0.7161      1.198   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.979      0.902      0.983      0.853      0.979      0.902      0.983      0.823\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      28/50      3.53G     0.7084     0.9494     0.3995     0.6996       1.17   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.975      0.962      0.989       0.85      0.963      0.951      0.987      0.762\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      29/50      3.53G     0.7543     0.9765     0.4125      0.702        1.2   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.966      0.951      0.988      0.852      0.963      0.949      0.968      0.775\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      30/50      3.53G     0.6946     0.8898     0.3784     0.6665      1.143   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.959      0.963      0.991      0.876      0.959      0.963      0.991      0.818\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      31/50      3.53G     0.7009     0.7511     0.3532     0.6788      1.167   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.964      0.983      0.993      0.887      0.964      0.983      0.993      0.829\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      32/50      3.53G     0.7305     0.9109     0.3739     0.6931      1.184   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976      0.999      0.995      0.912      0.976      0.999      0.995      0.878\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      33/50      3.53G     0.6446      0.753     0.3885     0.6212      1.127   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.999      0.995      0.915      0.988      0.987      0.985      0.866\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      34/50      3.53G     0.6243     0.7915     0.3452     0.5892      1.094   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.986          1      0.995      0.899      0.983      0.988      0.987      0.883\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      35/50      3.53G     0.6192     0.7736     0.3708     0.6105      1.102   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.987      0.988      0.994      0.899      0.987      0.988      0.986      0.893\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      36/50      3.53G     0.5915     0.7083     0.3632     0.5821      1.088   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.988      0.992      0.995      0.924      0.988      0.992      0.995      0.919\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      37/50      3.53G     0.6031     0.6441     0.3545      0.589      1.084   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.991      0.988      0.995      0.923      0.991      0.988      0.995      0.938\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      38/50      3.53G     0.5795     0.7106     0.3362     0.5735      1.085   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.996      0.995      0.906          1      0.996      0.995      0.931\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      39/50      3.53G     0.6032     0.6979     0.3605     0.5736      1.104   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976          1      0.995      0.913      0.976          1      0.995      0.943\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      40/50      3.53G     0.5582     0.6397     0.3205     0.5421       1.05   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976      0.994      0.994      0.926      0.976      0.994      0.994      0.939\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      41/50      3.53G     0.3974     0.4329     0.2155     0.4098     0.9377   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.965      0.999      0.992      0.919      0.965      0.999      0.992      0.933\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      42/50      3.53G      0.358     0.3314     0.2031     0.3709     0.8999   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976      0.987      0.992      0.921      0.976      0.987      0.992      0.945\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      43/50      3.53G     0.3675     0.3567     0.2106     0.3621     0.9108   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.975          1      0.994      0.934      0.975          1      0.994      0.952\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      44/50      3.53G     0.3755     0.3234     0.2184     0.3554     0.9211   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.975          1      0.994      0.931      0.975          1      0.994      0.946\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      45/50      3.53G     0.3711     0.3694     0.2086     0.3613      0.942   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.975      0.988      0.994      0.943      0.975      0.988      0.994      0.951\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      46/50      3.53G     0.3355     0.2745     0.1823     0.3218     0.9027   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976      0.987      0.994      0.947      0.976      0.987      0.994      0.963\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      47/50      3.53G     0.3253     0.2507     0.1783     0.3084     0.8873   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.995      0.976      0.994      0.948      0.995      0.976      0.994      0.961\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      48/50      3.53G     0.3394     0.2373     0.2025     0.3285     0.9061   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.993      0.963      0.993      0.944      0.993      0.963      0.993      0.966\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      49/50      3.53G     0.3101     0.1998     0.1648     0.3096     0.8924   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.988      0.965      0.994      0.947      0.988      0.965      0.994      0.961\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      50/50      3.53G     0.2954     0.2084     0.2094     0.3101     0.8685   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.991      0.976      0.994      0.947      0.991      0.976      0.994      0.964\n\n50 epochs completed in 0.240 hours.\nOptimizer stripped from Triangle_215/l_pretrain/weights/last.pt, 89.3MB\nOptimizer stripped from Triangle_215/l_pretrain/weights/best.pt, 89.3MB\n\nValidating Triangle_215/l_pretrain/weights/best.pt...\nUltralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLOv8l-pose summary (fused): 121 layers, 44,457,390 parameters, 0 gradients, 168.5 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.991      0.976      0.994      0.945      0.991      0.976      0.994      0.964\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nSpeed: 0.4ms preprocess, 21.9ms inference, 0.0ms loss, 4.3ms postprocess per image\nResults saved to \u001b[1mTriangle_215/l_pretrain\u001b[0m\nğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# yolov8x-poseæ¨¡å‹ï¼Œè¿ç§»å­¦ä¹ å¾®è°ƒ\n!yolo pose train data=Triangle_215.yaml model=yolov8x-pose.pt pretrained=True project=Triangle_215 name=x_pretrain epochs=50 batch=4 device=0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T14:48:55.014501Z","iopub.execute_input":"2025-03-26T14:48:55.014892Z","iopub.status.idle":"2025-03-26T15:09:11.322375Z","shell.execute_reply.started":"2025-03-26T14:48:55.014853Z","shell.execute_reply":"2025-03-26T15:09:11.321503Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x-pose.pt to 'yolov8x-pose.pt'...\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133M/133M [00:01<00:00, 106MB/s]\nUltralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=pose, mode=train, model=yolov8x-pose.pt, data=Triangle_215.yaml, epochs=50, time=None, patience=100, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=Triangle_215, name=x_pretrain, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=Triangle_215/x_pretrain\nOverriding model.yaml kpt_shape=[17, 3] with kpt_shape=[3, 3]\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n 22        [15, 18, 21]  1  10046878  ultralytics.nn.modules.head.Pose             [1, [3, 3], [320, 640, 640]]  \nYOLOv8x-pose summary: 224 layers, 69,481,518 parameters, 69,481,502 gradients, 263.9 GFLOPs\n\nTransferred 631/637 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir Triangle_215/x_pretrain', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/labels/train\u001b[0m\nWARNING âš ï¸ No 'flip_idx' array defined in data.yaml, setting augmentation 'fliplr=0.0'\n/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/labels/val.cac\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_153602.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_171841.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172124.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172345.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172510.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172619.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172846.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172857.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173044.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173224.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173349.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173410.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173729.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173738.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173752.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173812.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_174128.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_080946.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_080947.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_081012.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_081015.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082240.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082320.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082330.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082423.jpg: corrupt JPEG restored and saved\nPlotting labels to Triangle_215/x_pretrain/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 103 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mTriangle_215/x_pretrain\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       1/50      4.89G      1.468      4.296     0.6908      2.236      1.847   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82     0.0236      0.744     0.0212    0.00709     0.0202      0.646     0.0183    0.00448\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       2/50       4.9G      1.532      3.446     0.5951      1.783      1.848   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82    0.00132     0.0122   0.000671   6.71e-05     0.0862     0.0122    0.00483   0.000762\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       3/50       4.9G      1.693      3.454     0.6068      1.937      1.965   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82     0.0114      0.646    0.00952    0.00244    0.00326      0.232    0.00201   0.000459\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       4/50       4.9G      1.746      3.516     0.5842      1.913      2.011   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82     0.0417       0.28     0.0357     0.0111     0.0211       0.39     0.0142    0.00432\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       5/50       4.9G       1.64      3.085     0.5558      1.764      1.909   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82    0.00346      0.256    0.00217   0.000559     0.0317      0.402     0.0241    0.00557\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       6/50       4.9G       1.59      3.067     0.5697       1.69       1.87   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82     0.0517      0.488     0.0402     0.0153     0.0532      0.512     0.0444     0.0136\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       7/50       4.9G      1.541      2.792     0.5668       1.58      1.849   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.533      0.671      0.574      0.263      0.455      0.402      0.325      0.112\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       8/50       4.9G      1.358      2.431     0.5422      1.368      1.717   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.661      0.785      0.784      0.556       0.71      0.598      0.698       0.31\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       9/50       4.9G        1.3      2.398     0.5412      1.295      1.653   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.694      0.664      0.718      0.432      0.538      0.634      0.584      0.268\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      10/50       4.9G      1.325      2.201     0.5387      1.327      1.673   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.844       0.72      0.848      0.576      0.859      0.732      0.845      0.441\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      11/50       4.9G      1.157      1.924     0.5192      1.138      1.548   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.819      0.646      0.766      0.496      0.848      0.681        0.8      0.505\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      12/50       4.9G      1.128      1.905      0.532      1.127      1.549   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.823      0.738      0.854      0.628      0.797       0.72       0.78      0.462\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      13/50       4.9G      1.193       2.02     0.5075      1.139      1.578   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82       0.84      0.817      0.911      0.692       0.84      0.817      0.892      0.541\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      14/50       4.9G      1.099      1.665     0.4828      1.034      1.452   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.853      0.793      0.888       0.64      0.841      0.773      0.854      0.571\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      15/50       4.9G      1.073      1.646     0.4877      1.077      1.517   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.728      0.882      0.848      0.576      0.725       0.78      0.777      0.466\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      16/50       4.9G     0.9651      1.508     0.4772     0.9794      1.415   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82       0.97      0.792      0.925      0.713      0.953      0.793      0.913      0.641\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      17/50       4.9G     0.9967      1.439       0.46     0.9474      1.402   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.843      0.878       0.92      0.739       0.84        0.9      0.913      0.563\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      18/50       4.9G     0.9252      1.443      0.468     0.9144      1.353   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.887      0.915      0.963      0.784      0.887      0.915      0.959      0.685\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      19/50       4.9G     0.9204      1.302     0.4688     0.9124       1.35   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.903      0.841      0.928      0.754      0.903      0.841      0.918       0.69\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      20/50       4.9G     0.9107      1.295     0.4445     0.8996      1.356   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.962      0.924      0.973      0.806      0.908      0.878      0.933      0.734\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      21/50       4.9G     0.8692       1.15     0.4209     0.8395      1.312   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82       0.92      0.902      0.957      0.799      0.942      0.797      0.897      0.622\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      22/50       4.9G     0.9085      1.255     0.4368     0.8936      1.359   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.881      0.903      0.947      0.808      0.878      0.877      0.938      0.725\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      23/50       4.9G     0.9013      1.309     0.4466      0.852      1.327   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.905      0.951      0.966      0.795      0.893      0.939       0.94      0.719\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      24/50       4.9G     0.8318       1.22      0.418     0.8093      1.271   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.898      0.962       0.97      0.825      0.898      0.962      0.971      0.753\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      25/50       4.9G     0.7639       1.02     0.3969     0.7618      1.244   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.959      0.902      0.976      0.836      0.984      0.902      0.969      0.792\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      26/50       4.9G     0.7784      1.193     0.3977     0.7731      1.234   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.955      0.902      0.963      0.828      0.947       0.89      0.945      0.763\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      27/50       4.9G     0.7885     0.9871     0.4233     0.7495      1.256   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.895      0.963      0.974      0.815      0.895      0.963      0.974      0.737\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      28/50       4.9G     0.7646     0.9801     0.3934     0.7257      1.239   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.951      0.951       0.98      0.857      0.951      0.951      0.979      0.765\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      29/50       4.9G     0.7706     0.9692     0.3997     0.7246      1.226   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.944      0.927      0.974      0.842      0.956      0.939      0.974       0.82\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      30/50       4.9G      0.708     0.8868     0.3816     0.6889      1.174   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.941      0.927      0.974      0.819      0.925      0.951       0.97      0.794\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      31/50       4.9G     0.7192     0.8164     0.3473     0.7129      1.203   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.974      0.916      0.984      0.842      0.974      0.916      0.972      0.851\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      32/50       4.9G     0.7608     0.9636     0.3591     0.7393      1.222   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.996      0.939      0.988      0.864       0.97      0.951      0.981      0.819\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      33/50       4.9G     0.6673     0.7628     0.3776     0.6592      1.158   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.995      0.951      0.993      0.885      0.995      0.951      0.993      0.886\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      34/50       4.9G     0.6579     0.7622     0.3474     0.6433      1.129   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82       0.96          1      0.993      0.887      0.967      0.988      0.994        0.9\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      35/50       4.9G     0.6588     0.7281     0.3694      0.641      1.139   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.952          1      0.994      0.886      0.952          1       0.99      0.878\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      36/50       4.9G     0.6235     0.7256     0.3471     0.6171      1.114   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82       0.97      0.988      0.993      0.882       0.97      0.988      0.991      0.883\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      37/50       4.9G     0.6502     0.7041     0.3468     0.6422      1.131   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.987      0.939      0.985      0.884      0.971      0.963      0.984      0.892\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      38/50       4.9G     0.6291     0.7183     0.3435     0.6323      1.138   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82          1      0.933      0.979      0.899      0.992      0.951      0.987      0.884\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      39/50       4.9G     0.6323     0.7725     0.3605     0.6235       1.14   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.978      0.963      0.992      0.898          1      0.973      0.985      0.875\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      40/50       4.9G     0.5945     0.7133     0.3172      0.583      1.084   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.986          1      0.994      0.899      0.976      0.988      0.992        0.9\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      41/50       4.9G     0.4416     0.4023     0.2195     0.4712          1   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.957      0.988      0.988      0.915      0.942      0.986      0.989      0.933\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      42/50       4.9G     0.4093     0.3606     0.2102     0.4485     0.9531   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82       0.98      0.976      0.992      0.913      0.999      0.963      0.988      0.938\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      43/50       4.9G      0.402     0.3869     0.2232     0.4143     0.9621   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.971      0.988      0.993      0.919      0.986      0.976      0.993      0.942\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      44/50       4.9G     0.3985      0.325     0.2225     0.3961      0.964   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.968      0.976      0.994      0.913      0.988      0.966      0.993      0.944\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      45/50       4.9G     0.3906     0.3898     0.2038     0.4101     0.9764   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.962          1      0.994      0.943      0.997      0.951      0.993      0.932\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      46/50       4.9G     0.3719     0.2959     0.1878     0.3747     0.9369   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.988          1      0.995      0.937      0.984      0.988      0.994      0.945\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      47/50       4.9G     0.3704     0.2691     0.1771     0.3615     0.9308   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976          1      0.994      0.936      0.964      0.988      0.993      0.954\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      48/50       4.9G     0.3668     0.2633     0.2106     0.3735     0.9455   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.975          1      0.994      0.949      0.964      0.988      0.992      0.956\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      49/50       4.9G     0.3412     0.2417     0.1708     0.3573      0.926   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976          1      0.994      0.952      0.964      0.988      0.993      0.959\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      50/50       4.9G      0.341     0.2384     0.2166     0.3538     0.9005   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976      0.997      0.994      0.946      0.994      0.963      0.993      0.966\n\n50 epochs completed in 0.328 hours.\nOptimizer stripped from Triangle_215/x_pretrain/weights/last.pt, 139.4MB\nOptimizer stripped from Triangle_215/x_pretrain/weights/best.pt, 139.4MB\n\nValidating Triangle_215/x_pretrain/weights/best.pt...\nUltralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLOv8x-pose summary (fused): 121 layers, 69,451,998 parameters, 0 gradients, 263.2 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.976      0.997      0.994      0.946      0.994      0.963      0.993      0.966\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nSpeed: 0.4ms preprocess, 31.6ms inference, 0.0ms loss, 3.3ms postprocess per image\nResults saved to \u001b[1mTriangle_215/x_pretrain\u001b[0m\nğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# yolov8x-pose-p6æ¨¡å‹ï¼Œè¿ç§»å­¦ä¹ å¾®è°ƒ\n!yolo pose train data=Triangle_215.yaml model=yolov8x-pose-p6.pt pretrained=True imgsz=1280 project=Triangle_215 name=x_p6_pretrain epochs=50 batch=2 device=0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T15:10:12.112537Z","iopub.execute_input":"2025-03-26T15:10:12.112917Z","execution_failed":"2025-03-27T02:50:40.894Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x-pose-p6.pt to 'yolov8x-pose-p6.pt'...\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190M/190M [00:04<00:00, 41.8MB/s]\nUltralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=pose, mode=train, model=yolov8x-pose-p6.pt, data=Triangle_215.yaml, epochs=50, time=None, patience=100, batch=2, imgsz=1280, save=True, save_period=-1, cache=False, device=0, workers=8, project=Triangle_215, name=x_p6_pretrain, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=Triangle_215/x_p6_pretrain\nOverriding model.yaml kpt_shape=[17, 3] with kpt_shape=[3, 3]\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n  9                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n 10                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n 11                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 13             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 14                  -1  3   6764800  ultralytics.nn.modules.block.C2              [1280, 640, 3, False]         \n 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 16             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 17                  -1  3   6764800  ultralytics.nn.modules.block.C2              [1280, 640, 3, False]         \n 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 19             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 20                  -1  3   1795200  ultralytics.nn.modules.block.C2              [960, 320, 3, False]          \n 21                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n 22            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 23                  -1  3   6560000  ultralytics.nn.modules.block.C2              [960, 640, 3, False]          \n 24                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n 25            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 26                  -1  3   6764800  ultralytics.nn.modules.block.C2              [1280, 640, 3, False]         \n 27                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n 28            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 29                  -1  3   6764800  ultralytics.nn.modules.block.C2              [1280, 640, 3, False]         \n 30    [20, 23, 26, 29]  1  13856632  ultralytics.nn.modules.head.Pose             [1, [3, 3], [320, 640, 640, 640]]\nYOLOv8x-pose-p6 summary: 294 layers, 99,169,032 parameters, 99,169,016 gradients, 267.3 GFLOPs\n\nTransferred 827/835 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir Triangle_215/x_p6_pretrain', view at http://localhost:6006/\nFreezing layer 'model.30.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/labels/train\u001b[0m\nWARNING âš ï¸ No 'flip_idx' array defined in data.yaml, setting augmentation 'fliplr=0.0'\n/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/labels/val.cac\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_153602.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_171841.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172124.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172345.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172510.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172619.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172846.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_172857.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173044.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173224.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173349.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173410.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173729.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173738.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173752.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_173812.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/IMG_20230417_174128.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_080946.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_080947.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_081012.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_081015.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082240.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082320.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082330.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/val/MVIMG_20230331_082423.jpg: corrupt JPEG restored and saved\nPlotting labels to Triangle_215/x_p6_pretrain/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 135 weight(decay=0.0), 148 weight(decay=0.0005), 147 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 1280 train, 1280 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mTriangle_215/x_p6_pretrain\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       1/50      8.17G      1.441      4.333     0.6527      2.033      1.859   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.169      0.341      0.144     0.0542      0.123       0.39      0.089     0.0235\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       2/50      8.51G      1.985       4.17     0.6155      2.396      2.296   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82     0.0063      0.232    0.00392    0.00115    0.00133     0.0488   0.000642   7.95e-05\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       3/50      8.51G      2.388      4.184     0.6171      2.695      2.717   \n                 Class     Images  Instances      Box(P          R      mAP50  m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/validator.py:289: RuntimeWarning: invalid value encountered in greater_equal\n  matches = np.nonzero(iou >= threshold)  # IoU > threshold and classes match\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82    0.00481      0.756    0.00526    0.00116    0.00101      0.159   0.000879   0.000223\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       4/50      8.51G      2.341      4.127      0.624      2.585      2.718   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82    0.00619      0.744    0.00554    0.00186    0.00605      0.561    0.00595    0.00181\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       5/50      8.51G      2.311       4.14     0.5968      2.481      2.676   \n                 Class     Images  Instances      Box(P          R      mAP50  m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/validator.py:289: RuntimeWarning: invalid value encountered in greater_equal\n  matches = np.nonzero(iou >= threshold)  # IoU > threshold and classes match\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82    0.00363      0.561    0.00315    0.00115    0.00165      0.256    0.00103   0.000227\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       6/50      8.52G      2.341       3.98     0.5979      2.512      2.661   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82    0.00946      0.768     0.0102    0.00309     0.0046       0.39    0.00326   0.000743\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       7/50      8.52G      2.254      3.894     0.6032      2.417      2.523   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82     0.0117      0.402    0.00809    0.00254      0.017       0.28     0.0154    0.00336\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       8/50      8.52G      2.145      3.756     0.5855      2.329      2.527   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82    0.00257      0.378    0.00214   0.000561   0.000785      0.122   0.000437   0.000109\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n       9/50      8.52G      2.237      3.693     0.6088      2.423       2.59   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82       0.03      0.402     0.0254    0.00804     0.0313      0.415     0.0228    0.00673\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      10/50      8.52G      2.141      3.409      0.584      2.264      2.479   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.382      0.341      0.311      0.101      0.343       0.39      0.283      0.115\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      11/50      8.52G      2.127      3.296     0.5646      2.174       2.44   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82     0.0908      0.439     0.0672     0.0202      0.144      0.268     0.0909     0.0256\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      12/50      8.52G      2.042      3.208     0.5736      2.163      2.398   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.198      0.524      0.157     0.0651      0.194      0.451      0.163     0.0659\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      13/50      8.52G      1.952      3.041     0.5711      2.041      2.352   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.517      0.439      0.408      0.201        0.3      0.488      0.327      0.154\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      14/50      8.52G      1.852      2.967     0.5655      1.947      2.256   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82       0.63      0.427      0.538      0.262      0.649      0.402      0.535      0.222\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      15/50      8.52G      1.827      2.917     0.5645      1.842       2.22   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.677      0.562      0.679      0.306      0.521      0.634      0.568      0.299\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      16/50      8.52G      1.816      3.085     0.5615      1.817      2.221   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.443      0.602      0.536      0.285      0.404      0.622      0.481      0.312\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      17/50      8.52G      1.792      2.794      0.552      1.756      2.223   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.676      0.598      0.688      0.381      0.628      0.671       0.67      0.398\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      18/50      8.52G      1.701      2.775     0.5582      1.726      2.154   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.749      0.683      0.755      0.405       0.75       0.73      0.741      0.418\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      19/50      8.52G      1.647      2.515     0.5534      1.604      2.072   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.723      0.622      0.785      0.436      0.723       0.61      0.711      0.426\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n      20/50      8.52G       1.55      2.594     0.5413      1.589      2.009   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         43         82      0.811       0.73      0.823       0.48       0.74      0.707      0.752      0.495\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n  0%|          | 0/86 [00:00<?, ?it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport onnx\n\n# å¯¼å‡º ONNX\nmodel = YOLO('checkpoint/Triangle_215_yolov8l_pretrain.pt')\nmodel.export(format='onnx', imgsz=(640, 640), opset=12, simplify=True)\n\n# éªŒè¯\nonnx_model = onnx.load('Triangle_215_yolov8l_pretrain.onnx')\nonnx.checker.check_model(onnx_model)\nprint(\"âœ… å¯¼å‡ºæˆåŠŸï¼Œæ¨¡å‹ç»“æ„ï¼š\")\nprint(onnx.helper.printable_graph(onnx_model.graph))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!yolo export model=Triangle_215/x_pretrain/weights/best.pt format=onnx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:09:58.147927Z","iopub.execute_input":"2025-03-27T04:09:58.148199Z","iopub.status.idle":"2025-03-27T04:10:20.421469Z","shell.execute_reply.started":"2025-03-27T04:09:58.148178Z","shell.execute_reply":"2025-03-27T04:10:20.420435Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.00GHz)\nYOLOv8x-pose summary (fused): 121 layers, 69,451,998 parameters, 0 gradients, 263.2 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Triangle_215/x_pretrain/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 14, 8400) (132.9 MB)\n\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnxslim', 'onnxruntime'] not found, attempting AutoUpdate...\nCollecting onnxslim\n  Downloading onnxslim-0.1.48-py3-none-any.whl.metadata (4.6 kB)\nCollecting onnxruntime\n  Downloading onnxruntime-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\nRequirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnxslim) (1.17.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxslim) (1.13.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxslim) (24.2)\nCollecting coloredlogs (from onnxruntime)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\nRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (2.4.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxslim) (1.3.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.6->onnxruntime) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.6->onnxruntime) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.6->onnxruntime) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.6->onnxruntime) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.6->onnxruntime) (2024.2.0)\nDownloading onnxslim-0.1.48-py3-none-any.whl (142 kB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 142.9/142.9 kB 10.3 MB/s eta 0:00:00\nDownloading onnxruntime-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 16.0/16.0 MB 301.4 MB/s eta 0:00:00\nDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 46.0/46.0 kB 276.3 MB/s eta 0:00:00\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 86.8/86.8 kB 256.7 MB/s eta 0:00:00\nInstalling collected packages: humanfriendly, coloredlogs, onnxslim, onnxruntime\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.21.0 onnxslim-0.1.48\n\n\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 4.9s, installed 2 packages: ['onnxslim', 'onnxruntime']\n\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 12.2s, saved as 'Triangle_215/x_pretrain/weights/best.onnx' (265.3 MB)\n\nExport complete (18.5s)\nResults saved to \u001b[1m/kaggle/working/Triangle_215/x_pretrain/weights\u001b[0m\nPredict:         yolo predict task=pose model=Triangle_215/x_pretrain/weights/best.onnx imgsz=640  \nValidate:        yolo val task=pose model=Triangle_215/x_pretrain/weights/best.onnx imgsz=640 data=Triangle_215.yaml  \nVisualize:       https://netron.app\nğŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"yolo export model=Triangle_215/l_pretrain/weights/best.pt format=onnx","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!yolo export model=Triangle_215/m_pretrain/weights/best.pt format=onnx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:11:09.406431Z","iopub.execute_input":"2025-03-27T04:11:09.406766Z","iopub.status.idle":"2025-03-27T04:11:17.599057Z","shell.execute_reply.started":"2025-03-27T04:11:09.406740Z","shell.execute_reply":"2025-03-27T04:11:17.598182Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.00GHz)\nYOLOv8m-pose summary (fused): 101 layers, 26,401,822 parameters, 0 gradients, 80.8 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Triangle_215/m_pretrain/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 14, 8400) (50.7 MB)\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 2.7s, saved as 'Triangle_215/m_pretrain/weights/best.onnx' (101.0 MB)\n\nExport complete (4.7s)\nResults saved to \u001b[1m/kaggle/working/Triangle_215/m_pretrain/weights\u001b[0m\nPredict:         yolo predict task=pose model=Triangle_215/m_pretrain/weights/best.onnx imgsz=640  \nValidate:        yolo val task=pose model=Triangle_215/m_pretrain/weights/best.onnx imgsz=640 data=Triangle_215.yaml  \nVisualize:       https://netron.app\nğŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!yolo export model=Triangle_215/n_pretrain/weights/best.pt format=onnx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:11:35.551024Z","iopub.execute_input":"2025-03-27T04:11:35.551327Z","iopub.status.idle":"2025-03-27T04:11:40.492800Z","shell.execute_reply.started":"2025-03-27T04:11:35.551299Z","shell.execute_reply":"2025-03-27T04:11:40.491967Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.00GHz)\nYOLOv8n-pose summary (fused): 81 layers, 3,077,822 parameters, 0 gradients, 8.3 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Triangle_215/n_pretrain/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 14, 8400) (6.1 MB)\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.1s, saved as 'Triangle_215/n_pretrain/weights/best.onnx' (12.0 MB)\n\nExport complete (1.7s)\nResults saved to \u001b[1m/kaggle/working/Triangle_215/n_pretrain/weights\u001b[0m\nPredict:         yolo predict task=pose model=Triangle_215/n_pretrain/weights/best.onnx imgsz=640  \nValidate:        yolo val task=pose model=Triangle_215/n_pretrain/weights/best.onnx imgsz=640 data=Triangle_215.yaml  \nVisualize:       https://netron.app\nğŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!yolo export model=Triangle_215/s_pretrain/weights/best.pt format=onnx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:11:45.631018Z","iopub.execute_input":"2025-03-27T04:11:45.631309Z","iopub.status.idle":"2025-03-27T04:11:51.539954Z","shell.execute_reply.started":"2025-03-27T04:11:45.631285Z","shell.execute_reply":"2025-03-27T04:11:51.539105Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.00GHz)\nYOLOv8s-pose summary (fused): 81 layers, 11,412,750 parameters, 0 gradients, 29.4 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Triangle_215/s_pretrain/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 14, 8400) (22.0 MB)\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.7s, saved as 'Triangle_215/s_pretrain/weights/best.onnx' (43.8 MB)\n\nExport complete (2.6s)\nResults saved to \u001b[1m/kaggle/working/Triangle_215/s_pretrain/weights\u001b[0m\nPredict:         yolo predict task=pose model=Triangle_215/s_pretrain/weights/best.onnx imgsz=640  \nValidate:        yolo val task=pose model=Triangle_215/s_pretrain/weights/best.onnx imgsz=640 data=Triangle_215.yaml  \nVisualize:       https://netron.app\nğŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!yolo export model=Triangle_215/x_p6_pretrain/weights/best.pt format=onnx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:11:57.719947Z","iopub.execute_input":"2025-03-27T04:11:57.720245Z","iopub.status.idle":"2025-03-27T04:12:31.381216Z","shell.execute_reply.started":"2025-03-27T04:11:57.720218Z","shell.execute_reply":"2025-03-27T04:12:31.380378Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.00GHz)\nYOLOv8x-pose-p6 summary (fused): 159 layers, 99,127,672 parameters, 0 gradients, 266.5 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Triangle_215/x_p6_pretrain/weights/best.pt' with input shape (1, 3, 1280, 1280) BCHW and output shape(s) (1, 14, 34000) (189.8 MB)\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 14.8s, saved as 'Triangle_215/x_p6_pretrain/weights/best.onnx' (379.2 MB)\n\nExport complete (29.7s)\nResults saved to \u001b[1m/kaggle/working/Triangle_215/x_p6_pretrain/weights\u001b[0m\nPredict:         yolo predict task=pose model=Triangle_215/x_p6_pretrain/weights/best.onnx imgsz=1280  \nValidate:        yolo val task=pose model=Triangle_215/x_p6_pretrain/weights/best.onnx imgsz=1280 data=Triangle_215.yaml  \nVisualize:       https://netron.app\nğŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import onnx\n\n# è¯»å– ONNX æ¨¡å‹\nonnx_model = onnx.load('Triangle_215/x_p6_pretrain/weights/best.onnx')\n\n# æ£€æŸ¥æ¨¡å‹æ ¼å¼æ˜¯å¦æ­£ç¡®\nonnx.checker.check_model(onnx_model)\n\nprint('æ— æŠ¥é”™ï¼Œonnxæ¨¡å‹è½½å…¥æˆåŠŸ')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:13:57.494886Z","iopub.execute_input":"2025-03-27T04:13:57.495200Z","iopub.status.idle":"2025-03-27T04:13:58.877334Z","shell.execute_reply.started":"2025-03-27T04:13:57.495173Z","shell.execute_reply":"2025-03-27T04:13:58.876607Z"}},"outputs":[{"name":"stdout","text":"æ— æŠ¥é”™ï¼Œonnxæ¨¡å‹è½½å…¥æˆåŠŸ\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(onnx.helper.printable_graph(onnx_model.graph))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:14:41.894932Z","iopub.execute_input":"2025-03-27T04:14:41.895397Z","iopub.status.idle":"2025-03-27T04:14:41.913437Z","shell.execute_reply.started":"2025-03-27T04:14:41.895371Z","shell.execute_reply":"2025-03-27T04:14:41.908675Z"}},"outputs":[{"name":"stdout","text":"graph main_graph (\n  %images[FLOAT, 1x3x1280x1280]\n) initializers (\n  %model.0.conv.weight[FLOAT, 80x3x3x3]\n  %model.0.conv.bias[FLOAT, 80]\n  %model.1.conv.weight[FLOAT, 160x80x3x3]\n  %model.1.conv.bias[FLOAT, 160]\n  %model.2.cv1.conv.weight[FLOAT, 160x160x1x1]\n  %model.2.cv1.conv.bias[FLOAT, 160]\n  %onnx::Split_306[INT64, 2]\n  %model.2.m.0.cv1.conv.weight[FLOAT, 80x80x3x3]\n  %model.2.m.0.cv1.conv.bias[FLOAT, 80]\n  %model.2.m.0.cv2.conv.weight[FLOAT, 80x80x3x3]\n  %model.2.m.0.cv2.conv.bias[FLOAT, 80]\n  %model.2.m.1.cv1.conv.weight[FLOAT, 80x80x3x3]\n  %model.2.m.1.cv1.conv.bias[FLOAT, 80]\n  %model.2.m.1.cv2.conv.weight[FLOAT, 80x80x3x3]\n  %model.2.m.1.cv2.conv.bias[FLOAT, 80]\n  %model.2.m.2.cv1.conv.weight[FLOAT, 80x80x3x3]\n  %model.2.m.2.cv1.conv.bias[FLOAT, 80]\n  %model.2.m.2.cv2.conv.weight[FLOAT, 80x80x3x3]\n  %model.2.m.2.cv2.conv.bias[FLOAT, 80]\n  %model.2.cv2.conv.weight[FLOAT, 160x400x1x1]\n  %model.2.cv2.conv.bias[FLOAT, 160]\n  %model.3.conv.weight[FLOAT, 320x160x3x3]\n  %model.3.conv.bias[FLOAT, 320]\n  %model.4.cv1.conv.weight[FLOAT, 320x320x1x1]\n  %model.4.cv1.conv.bias[FLOAT, 320]\n  %onnx::Split_340[INT64, 2]\n  %model.4.m.0.cv1.conv.weight[FLOAT, 160x160x3x3]\n  %model.4.m.0.cv1.conv.bias[FLOAT, 160]\n  %model.4.m.0.cv2.conv.weight[FLOAT, 160x160x3x3]\n  %model.4.m.0.cv2.conv.bias[FLOAT, 160]\n  %model.4.m.1.cv1.conv.weight[FLOAT, 160x160x3x3]\n  %model.4.m.1.cv1.conv.bias[FLOAT, 160]\n  %model.4.m.1.cv2.conv.weight[FLOAT, 160x160x3x3]\n  %model.4.m.1.cv2.conv.bias[FLOAT, 160]\n  %model.4.m.2.cv1.conv.weight[FLOAT, 160x160x3x3]\n  %model.4.m.2.cv1.conv.bias[FLOAT, 160]\n  %model.4.m.2.cv2.conv.weight[FLOAT, 160x160x3x3]\n  %model.4.m.2.cv2.conv.bias[FLOAT, 160]\n  %model.4.m.3.cv1.conv.weight[FLOAT, 160x160x3x3]\n  %model.4.m.3.cv1.conv.bias[FLOAT, 160]\n  %model.4.m.3.cv2.conv.weight[FLOAT, 160x160x3x3]\n  %model.4.m.3.cv2.conv.bias[FLOAT, 160]\n  %model.4.m.4.cv1.conv.weight[FLOAT, 160x160x3x3]\n  %model.4.m.4.cv1.conv.bias[FLOAT, 160]\n  %model.4.m.4.cv2.conv.weight[FLOAT, 160x160x3x3]\n  %model.4.m.4.cv2.conv.bias[FLOAT, 160]\n  %model.4.m.5.cv1.conv.weight[FLOAT, 160x160x3x3]\n  %model.4.m.5.cv1.conv.bias[FLOAT, 160]\n  %model.4.m.5.cv2.conv.weight[FLOAT, 160x160x3x3]\n  %model.4.m.5.cv2.conv.bias[FLOAT, 160]\n  %model.4.cv2.conv.weight[FLOAT, 320x1280x1x1]\n  %model.4.cv2.conv.bias[FLOAT, 320]\n  %model.5.conv.weight[FLOAT, 640x320x3x3]\n  %model.5.conv.bias[FLOAT, 640]\n  %model.6.cv1.conv.weight[FLOAT, 640x640x1x1]\n  %model.6.cv1.conv.bias[FLOAT, 640]\n  %onnx::Split_395[INT64, 2]\n  %model.6.m.0.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.6.m.0.cv1.conv.bias[FLOAT, 320]\n  %model.6.m.0.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.6.m.0.cv2.conv.bias[FLOAT, 320]\n  %model.6.m.1.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.6.m.1.cv1.conv.bias[FLOAT, 320]\n  %model.6.m.1.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.6.m.1.cv2.conv.bias[FLOAT, 320]\n  %model.6.m.2.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.6.m.2.cv1.conv.bias[FLOAT, 320]\n  %model.6.m.2.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.6.m.2.cv2.conv.bias[FLOAT, 320]\n  %model.6.m.3.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.6.m.3.cv1.conv.bias[FLOAT, 320]\n  %model.6.m.3.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.6.m.3.cv2.conv.bias[FLOAT, 320]\n  %model.6.m.4.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.6.m.4.cv1.conv.bias[FLOAT, 320]\n  %model.6.m.4.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.6.m.4.cv2.conv.bias[FLOAT, 320]\n  %model.6.m.5.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.6.m.5.cv1.conv.bias[FLOAT, 320]\n  %model.6.m.5.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.6.m.5.cv2.conv.bias[FLOAT, 320]\n  %model.6.cv2.conv.weight[FLOAT, 640x2560x1x1]\n  %model.6.cv2.conv.bias[FLOAT, 640]\n  %model.7.conv.weight[FLOAT, 640x640x3x3]\n  %model.7.conv.bias[FLOAT, 640]\n  %model.8.cv1.conv.weight[FLOAT, 640x640x1x1]\n  %model.8.cv1.conv.bias[FLOAT, 640]\n  %model.8.m.0.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.8.m.0.cv1.conv.bias[FLOAT, 320]\n  %model.8.m.0.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.8.m.0.cv2.conv.bias[FLOAT, 320]\n  %model.8.m.1.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.8.m.1.cv1.conv.bias[FLOAT, 320]\n  %model.8.m.1.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.8.m.1.cv2.conv.bias[FLOAT, 320]\n  %model.8.m.2.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.8.m.2.cv1.conv.bias[FLOAT, 320]\n  %model.8.m.2.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.8.m.2.cv2.conv.bias[FLOAT, 320]\n  %model.8.cv2.conv.weight[FLOAT, 640x1600x1x1]\n  %model.8.cv2.conv.bias[FLOAT, 640]\n  %model.9.conv.weight[FLOAT, 640x640x3x3]\n  %model.9.conv.bias[FLOAT, 640]\n  %model.10.cv1.conv.weight[FLOAT, 640x640x1x1]\n  %model.10.cv1.conv.bias[FLOAT, 640]\n  %model.10.m.0.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.10.m.0.cv1.conv.bias[FLOAT, 320]\n  %model.10.m.0.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.10.m.0.cv2.conv.bias[FLOAT, 320]\n  %model.10.m.1.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.10.m.1.cv1.conv.bias[FLOAT, 320]\n  %model.10.m.1.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.10.m.1.cv2.conv.bias[FLOAT, 320]\n  %model.10.m.2.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.10.m.2.cv1.conv.bias[FLOAT, 320]\n  %model.10.m.2.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.10.m.2.cv2.conv.bias[FLOAT, 320]\n  %model.10.cv2.conv.weight[FLOAT, 640x1600x1x1]\n  %model.10.cv2.conv.bias[FLOAT, 640]\n  %model.11.cv1.conv.weight[FLOAT, 320x640x1x1]\n  %model.11.cv1.conv.bias[FLOAT, 320]\n  %model.11.cv2.conv.weight[FLOAT, 640x1280x1x1]\n  %model.11.cv2.conv.bias[FLOAT, 640]\n  %/model.12/Constant_output_0[FLOAT, 4]\n  %model.14.cv1.conv.weight[FLOAT, 640x1280x1x1]\n  %model.14.cv1.conv.bias[FLOAT, 640]\n  %/model.14/Constant_1_output_0[INT64, 1]\n  %/model.14/Mul_output_0[INT64, 1]\n  %/model.14/Constant_output_0[INT64, 1]\n  %/model.14/Mul_1_output_0[INT64, 1]\n  %model.14.m.0.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.14.m.0.cv1.conv.bias[FLOAT, 320]\n  %model.14.m.0.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.14.m.0.cv2.conv.bias[FLOAT, 320]\n  %model.14.m.1.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.14.m.1.cv1.conv.bias[FLOAT, 320]\n  %model.14.m.1.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.14.m.1.cv2.conv.bias[FLOAT, 320]\n  %model.14.m.2.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.14.m.2.cv1.conv.bias[FLOAT, 320]\n  %model.14.m.2.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.14.m.2.cv2.conv.bias[FLOAT, 320]\n  %model.14.cv2.conv.weight[FLOAT, 640x640x1x1]\n  %model.14.cv2.conv.bias[FLOAT, 640]\n  %model.17.cv1.conv.weight[FLOAT, 640x1280x1x1]\n  %model.17.cv1.conv.bias[FLOAT, 640]\n  %model.17.m.0.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.17.m.0.cv1.conv.bias[FLOAT, 320]\n  %model.17.m.0.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.17.m.0.cv2.conv.bias[FLOAT, 320]\n  %model.17.m.1.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.17.m.1.cv1.conv.bias[FLOAT, 320]\n  %model.17.m.1.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.17.m.1.cv2.conv.bias[FLOAT, 320]\n  %model.17.m.2.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.17.m.2.cv1.conv.bias[FLOAT, 320]\n  %model.17.m.2.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.17.m.2.cv2.conv.bias[FLOAT, 320]\n  %model.17.cv2.conv.weight[FLOAT, 640x640x1x1]\n  %model.17.cv2.conv.bias[FLOAT, 640]\n  %model.20.cv1.conv.weight[FLOAT, 320x960x1x1]\n  %model.20.cv1.conv.bias[FLOAT, 320]\n  %/model.20/Mul_output_0[INT64, 1]\n  %model.20.m.0.cv1.conv.weight[FLOAT, 160x160x3x3]\n  %model.20.m.0.cv1.conv.bias[FLOAT, 160]\n  %model.20.m.0.cv2.conv.weight[FLOAT, 160x160x3x3]\n  %model.20.m.0.cv2.conv.bias[FLOAT, 160]\n  %model.20.m.1.cv1.conv.weight[FLOAT, 160x160x3x3]\n  %model.20.m.1.cv1.conv.bias[FLOAT, 160]\n  %model.20.m.1.cv2.conv.weight[FLOAT, 160x160x3x3]\n  %model.20.m.1.cv2.conv.bias[FLOAT, 160]\n  %model.20.m.2.cv1.conv.weight[FLOAT, 160x160x3x3]\n  %model.20.m.2.cv1.conv.bias[FLOAT, 160]\n  %model.20.m.2.cv2.conv.weight[FLOAT, 160x160x3x3]\n  %model.20.m.2.cv2.conv.bias[FLOAT, 160]\n  %model.20.cv2.conv.weight[FLOAT, 320x320x1x1]\n  %model.20.cv2.conv.bias[FLOAT, 320]\n  %model.21.conv.weight[FLOAT, 320x320x3x3]\n  %model.21.conv.bias[FLOAT, 320]\n  %model.30.cv4.0.0.conv.weight[FLOAT, 80x320x3x3]\n  %model.30.cv4.0.0.conv.bias[FLOAT, 80]\n  %model.30.cv2.0.0.conv.weight[FLOAT, 80x320x3x3]\n  %model.30.cv2.0.0.conv.bias[FLOAT, 80]\n  %model.30.cv3.0.0.conv.weight[FLOAT, 320x320x3x3]\n  %model.30.cv3.0.0.conv.bias[FLOAT, 320]\n  %model.30.cv4.0.1.conv.weight[FLOAT, 80x80x3x3]\n  %model.30.cv4.0.1.conv.bias[FLOAT, 80]\n  %model.30.cv2.0.1.conv.weight[FLOAT, 80x80x3x3]\n  %model.30.cv2.0.1.conv.bias[FLOAT, 80]\n  %model.30.cv3.0.1.conv.weight[FLOAT, 320x320x3x3]\n  %model.30.cv3.0.1.conv.bias[FLOAT, 320]\n  %model.23.cv1.conv.weight[FLOAT, 640x960x1x1]\n  %model.23.cv1.conv.bias[FLOAT, 640]\n  %model.30.cv4.0.2.weight[FLOAT, 9x80x1x1]\n  %model.30.cv4.0.2.bias[FLOAT, 9]\n  %model.30.cv2.0.2.weight[FLOAT, 64x80x1x1]\n  %model.30.cv2.0.2.bias[FLOAT, 64]\n  %model.30.cv3.0.2.weight[FLOAT, 1x320x1x1]\n  %model.30.cv3.0.2.bias[FLOAT, 1]\n  %/model.30/Constant_output_0[INT64, 3]\n  %/model.30/Constant_5_output_0[INT64, 3]\n  %model.23.m.0.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.23.m.0.cv1.conv.bias[FLOAT, 320]\n  %model.23.m.0.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.23.m.0.cv2.conv.bias[FLOAT, 320]\n  %model.23.m.1.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.23.m.1.cv1.conv.bias[FLOAT, 320]\n  %model.23.m.1.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.23.m.1.cv2.conv.bias[FLOAT, 320]\n  %model.23.m.2.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.23.m.2.cv1.conv.bias[FLOAT, 320]\n  %model.23.m.2.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.23.m.2.cv2.conv.bias[FLOAT, 320]\n  %model.23.cv2.conv.weight[FLOAT, 640x640x1x1]\n  %model.23.cv2.conv.bias[FLOAT, 640]\n  %model.24.conv.weight[FLOAT, 640x640x3x3]\n  %model.24.conv.bias[FLOAT, 640]\n  %model.30.cv4.1.0.conv.weight[FLOAT, 80x640x3x3]\n  %model.30.cv4.1.0.conv.bias[FLOAT, 80]\n  %model.30.cv2.1.0.conv.weight[FLOAT, 80x640x3x3]\n  %model.30.cv2.1.0.conv.bias[FLOAT, 80]\n  %model.30.cv3.1.0.conv.weight[FLOAT, 320x640x3x3]\n  %model.30.cv3.1.0.conv.bias[FLOAT, 320]\n  %model.30.cv4.1.1.conv.weight[FLOAT, 80x80x3x3]\n  %model.30.cv4.1.1.conv.bias[FLOAT, 80]\n  %model.30.cv2.1.1.conv.weight[FLOAT, 80x80x3x3]\n  %model.30.cv2.1.1.conv.bias[FLOAT, 80]\n  %model.30.cv3.1.1.conv.weight[FLOAT, 320x320x3x3]\n  %model.30.cv3.1.1.conv.bias[FLOAT, 320]\n  %model.26.cv1.conv.weight[FLOAT, 640x1280x1x1]\n  %model.26.cv1.conv.bias[FLOAT, 640]\n  %model.30.cv4.1.2.weight[FLOAT, 9x80x1x1]\n  %model.30.cv4.1.2.bias[FLOAT, 9]\n  %model.30.cv2.1.2.weight[FLOAT, 64x80x1x1]\n  %model.30.cv2.1.2.bias[FLOAT, 64]\n  %model.30.cv3.1.2.weight[FLOAT, 1x320x1x1]\n  %model.30.cv3.1.2.bias[FLOAT, 1]\n  %model.26.m.0.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.26.m.0.cv1.conv.bias[FLOAT, 320]\n  %model.26.m.0.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.26.m.0.cv2.conv.bias[FLOAT, 320]\n  %model.26.m.1.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.26.m.1.cv1.conv.bias[FLOAT, 320]\n  %model.26.m.1.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.26.m.1.cv2.conv.bias[FLOAT, 320]\n  %model.26.m.2.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.26.m.2.cv1.conv.bias[FLOAT, 320]\n  %model.26.m.2.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.26.m.2.cv2.conv.bias[FLOAT, 320]\n  %model.26.cv2.conv.weight[FLOAT, 640x640x1x1]\n  %model.26.cv2.conv.bias[FLOAT, 640]\n  %model.27.conv.weight[FLOAT, 640x640x3x3]\n  %model.27.conv.bias[FLOAT, 640]\n  %model.30.cv4.2.0.conv.weight[FLOAT, 80x640x3x3]\n  %model.30.cv4.2.0.conv.bias[FLOAT, 80]\n  %model.30.cv2.2.0.conv.weight[FLOAT, 80x640x3x3]\n  %model.30.cv2.2.0.conv.bias[FLOAT, 80]\n  %model.30.cv3.2.0.conv.weight[FLOAT, 320x640x3x3]\n  %model.30.cv3.2.0.conv.bias[FLOAT, 320]\n  %model.30.cv4.2.1.conv.weight[FLOAT, 80x80x3x3]\n  %model.30.cv4.2.1.conv.bias[FLOAT, 80]\n  %model.30.cv2.2.1.conv.weight[FLOAT, 80x80x3x3]\n  %model.30.cv2.2.1.conv.bias[FLOAT, 80]\n  %model.30.cv3.2.1.conv.weight[FLOAT, 320x320x3x3]\n  %model.30.cv3.2.1.conv.bias[FLOAT, 320]\n  %model.29.cv1.conv.weight[FLOAT, 640x1280x1x1]\n  %model.29.cv1.conv.bias[FLOAT, 640]\n  %model.30.cv4.2.2.weight[FLOAT, 9x80x1x1]\n  %model.30.cv4.2.2.bias[FLOAT, 9]\n  %model.30.cv2.2.2.weight[FLOAT, 64x80x1x1]\n  %model.30.cv2.2.2.bias[FLOAT, 64]\n  %model.30.cv3.2.2.weight[FLOAT, 1x320x1x1]\n  %model.30.cv3.2.2.bias[FLOAT, 1]\n  %model.29.m.0.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.29.m.0.cv1.conv.bias[FLOAT, 320]\n  %model.29.m.0.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.29.m.0.cv2.conv.bias[FLOAT, 320]\n  %model.29.m.1.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.29.m.1.cv1.conv.bias[FLOAT, 320]\n  %model.29.m.1.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.29.m.1.cv2.conv.bias[FLOAT, 320]\n  %model.29.m.2.cv1.conv.weight[FLOAT, 320x320x3x3]\n  %model.29.m.2.cv1.conv.bias[FLOAT, 320]\n  %model.29.m.2.cv2.conv.weight[FLOAT, 320x320x3x3]\n  %model.29.m.2.cv2.conv.bias[FLOAT, 320]\n  %model.29.cv2.conv.weight[FLOAT, 640x640x1x1]\n  %model.29.cv2.conv.bias[FLOAT, 640]\n  %model.30.cv4.3.0.conv.weight[FLOAT, 80x640x3x3]\n  %model.30.cv4.3.0.conv.bias[FLOAT, 80]\n  %model.30.cv2.3.0.conv.weight[FLOAT, 80x640x3x3]\n  %model.30.cv2.3.0.conv.bias[FLOAT, 80]\n  %model.30.cv3.3.0.conv.weight[FLOAT, 320x640x3x3]\n  %model.30.cv3.3.0.conv.bias[FLOAT, 320]\n  %model.30.cv4.3.1.conv.weight[FLOAT, 80x80x3x3]\n  %model.30.cv4.3.1.conv.bias[FLOAT, 80]\n  %model.30.cv2.3.1.conv.weight[FLOAT, 80x80x3x3]\n  %model.30.cv2.3.1.conv.bias[FLOAT, 80]\n  %model.30.cv3.3.1.conv.weight[FLOAT, 320x320x3x3]\n  %model.30.cv3.3.1.conv.bias[FLOAT, 320]\n  %model.30.cv4.3.2.weight[FLOAT, 9x80x1x1]\n  %model.30.cv4.3.2.bias[FLOAT, 9]\n  %model.30.cv2.3.2.weight[FLOAT, 64x80x1x1]\n  %model.30.cv2.3.2.bias[FLOAT, 64]\n  %model.30.cv3.3.2.weight[FLOAT, 1x320x1x1]\n  %model.30.cv3.3.2.bias[FLOAT, 1]\n  %/model.30/Constant_19_output_0[INT64, 4]\n  %onnx::Split_952[INT64, 2]\n  %/model.30/Constant_22_output_0[INT64, 1]\n  %/model.30/Constant_29_output_0[INT64, 1]\n  %/model.30/dfl/Constant_output_0[INT64, 4]\n  %/model.30/Constant_24_output_0[FLOAT, scalar]\n  %/model.30/Constant_25_output_0[FLOAT, 2x34000]\n  %/model.30/Constant_26_output_0[FLOAT, 1x34000]\n  %model.30.dfl.conv.weight[FLOAT, 1x16x1x1]\n  %/model.30/dfl/Constant_1_output_0[INT64, 3]\n  %/model.30/Mul_1_output_0[INT64, 1]\n  %/model.30/Constant_15_output_0[FLOAT, 1x2x34000]\n  %/model.30/Constant_16_output_0[FLOAT, 1x2x34000]\n) {\n  %/model.0/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%images, %model.0.conv.weight, %model.0.conv.bias)\n  %/model.0/act/Sigmoid_output_0 = Sigmoid(%/model.0/conv/Conv_output_0)\n  %/model.0/act/Mul_output_0 = Mul(%/model.0/conv/Conv_output_0, %/model.0/act/Sigmoid_output_0)\n  %/model.1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/model.0/act/Mul_output_0, %model.1.conv.weight, %model.1.conv.bias)\n  %/model.1/act/Sigmoid_output_0 = Sigmoid(%/model.1/conv/Conv_output_0)\n  %/model.1/act/Mul_output_0 = Mul(%/model.1/conv/Conv_output_0, %/model.1/act/Sigmoid_output_0)\n  %/model.2/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.1/act/Mul_output_0, %model.2.cv1.conv.weight, %model.2.cv1.conv.bias)\n  %/model.2/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.2/cv1/conv/Conv_output_0)\n  %/model.2/cv1/act/Mul_output_0 = Mul(%/model.2/cv1/conv/Conv_output_0, %/model.2/cv1/act/Sigmoid_output_0)\n  %/model.2/Split_output_0, %/model.2/Split_output_1 = Split[axis = 1](%/model.2/cv1/act/Mul_output_0, %onnx::Split_306)\n  %/model.2/m.0/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.2/Split_output_1, %model.2.m.0.cv1.conv.weight, %model.2.m.0.cv1.conv.bias)\n  %/model.2/m.0/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.2/m.0/cv1/conv/Conv_output_0)\n  %/model.2/m.0/cv1/act/Mul_output_0 = Mul(%/model.2/m.0/cv1/conv/Conv_output_0, %/model.2/m.0/cv1/act/Sigmoid_output_0)\n  %/model.2/m.0/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.2/m.0/cv1/act/Mul_output_0, %model.2.m.0.cv2.conv.weight, %model.2.m.0.cv2.conv.bias)\n  %/model.2/m.0/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.2/m.0/cv2/conv/Conv_output_0)\n  %/model.2/m.0/cv2/act/Mul_output_0 = Mul(%/model.2/m.0/cv2/conv/Conv_output_0, %/model.2/m.0/cv2/act/Sigmoid_output_0)\n  %/model.2/m.0/Add_output_0 = Add(%/model.2/Split_output_1, %/model.2/m.0/cv2/act/Mul_output_0)\n  %/model.2/m.1/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.2/m.0/Add_output_0, %model.2.m.1.cv1.conv.weight, %model.2.m.1.cv1.conv.bias)\n  %/model.2/m.1/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.2/m.1/cv1/conv/Conv_output_0)\n  %/model.2/m.1/cv1/act/Mul_output_0 = Mul(%/model.2/m.1/cv1/conv/Conv_output_0, %/model.2/m.1/cv1/act/Sigmoid_output_0)\n  %/model.2/m.1/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.2/m.1/cv1/act/Mul_output_0, %model.2.m.1.cv2.conv.weight, %model.2.m.1.cv2.conv.bias)\n  %/model.2/m.1/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.2/m.1/cv2/conv/Conv_output_0)\n  %/model.2/m.1/cv2/act/Mul_output_0 = Mul(%/model.2/m.1/cv2/conv/Conv_output_0, %/model.2/m.1/cv2/act/Sigmoid_output_0)\n  %/model.2/m.1/Add_output_0 = Add(%/model.2/m.0/Add_output_0, %/model.2/m.1/cv2/act/Mul_output_0)\n  %/model.2/m.2/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.2/m.1/Add_output_0, %model.2.m.2.cv1.conv.weight, %model.2.m.2.cv1.conv.bias)\n  %/model.2/m.2/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.2/m.2/cv1/conv/Conv_output_0)\n  %/model.2/m.2/cv1/act/Mul_output_0 = Mul(%/model.2/m.2/cv1/conv/Conv_output_0, %/model.2/m.2/cv1/act/Sigmoid_output_0)\n  %/model.2/m.2/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.2/m.2/cv1/act/Mul_output_0, %model.2.m.2.cv2.conv.weight, %model.2.m.2.cv2.conv.bias)\n  %/model.2/m.2/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.2/m.2/cv2/conv/Conv_output_0)\n  %/model.2/m.2/cv2/act/Mul_output_0 = Mul(%/model.2/m.2/cv2/conv/Conv_output_0, %/model.2/m.2/cv2/act/Sigmoid_output_0)\n  %/model.2/m.2/Add_output_0 = Add(%/model.2/m.1/Add_output_0, %/model.2/m.2/cv2/act/Mul_output_0)\n  %/model.2/Concat_output_0 = Concat[axis = 1](%/model.2/Split_output_0, %/model.2/Split_output_1, %/model.2/m.0/Add_output_0, %/model.2/m.1/Add_output_0, %/model.2/m.2/Add_output_0)\n  %/model.2/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.2/Concat_output_0, %model.2.cv2.conv.weight, %model.2.cv2.conv.bias)\n  %/model.2/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.2/cv2/conv/Conv_output_0)\n  %/model.2/cv2/act/Mul_output_0 = Mul(%/model.2/cv2/conv/Conv_output_0, %/model.2/cv2/act/Sigmoid_output_0)\n  %/model.3/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/model.2/cv2/act/Mul_output_0, %model.3.conv.weight, %model.3.conv.bias)\n  %/model.3/act/Sigmoid_output_0 = Sigmoid(%/model.3/conv/Conv_output_0)\n  %/model.3/act/Mul_output_0 = Mul(%/model.3/conv/Conv_output_0, %/model.3/act/Sigmoid_output_0)\n  %/model.4/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.3/act/Mul_output_0, %model.4.cv1.conv.weight, %model.4.cv1.conv.bias)\n  %/model.4/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.4/cv1/conv/Conv_output_0)\n  %/model.4/cv1/act/Mul_output_0 = Mul(%/model.4/cv1/conv/Conv_output_0, %/model.4/cv1/act/Sigmoid_output_0)\n  %/model.4/Split_output_0, %/model.4/Split_output_1 = Split[axis = 1](%/model.4/cv1/act/Mul_output_0, %onnx::Split_340)\n  %/model.4/m.0/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.4/Split_output_1, %model.4.m.0.cv1.conv.weight, %model.4.m.0.cv1.conv.bias)\n  %/model.4/m.0/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.4/m.0/cv1/conv/Conv_output_0)\n  %/model.4/m.0/cv1/act/Mul_output_0 = Mul(%/model.4/m.0/cv1/conv/Conv_output_0, %/model.4/m.0/cv1/act/Sigmoid_output_0)\n  %/model.4/m.0/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.4/m.0/cv1/act/Mul_output_0, %model.4.m.0.cv2.conv.weight, %model.4.m.0.cv2.conv.bias)\n  %/model.4/m.0/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.4/m.0/cv2/conv/Conv_output_0)\n  %/model.4/m.0/cv2/act/Mul_output_0 = Mul(%/model.4/m.0/cv2/conv/Conv_output_0, %/model.4/m.0/cv2/act/Sigmoid_output_0)\n  %/model.4/m.0/Add_output_0 = Add(%/model.4/Split_output_1, %/model.4/m.0/cv2/act/Mul_output_0)\n  %/model.4/m.1/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.4/m.0/Add_output_0, %model.4.m.1.cv1.conv.weight, %model.4.m.1.cv1.conv.bias)\n  %/model.4/m.1/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.4/m.1/cv1/conv/Conv_output_0)\n  %/model.4/m.1/cv1/act/Mul_output_0 = Mul(%/model.4/m.1/cv1/conv/Conv_output_0, %/model.4/m.1/cv1/act/Sigmoid_output_0)\n  %/model.4/m.1/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.4/m.1/cv1/act/Mul_output_0, %model.4.m.1.cv2.conv.weight, %model.4.m.1.cv2.conv.bias)\n  %/model.4/m.1/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.4/m.1/cv2/conv/Conv_output_0)\n  %/model.4/m.1/cv2/act/Mul_output_0 = Mul(%/model.4/m.1/cv2/conv/Conv_output_0, %/model.4/m.1/cv2/act/Sigmoid_output_0)\n  %/model.4/m.1/Add_output_0 = Add(%/model.4/m.0/Add_output_0, %/model.4/m.1/cv2/act/Mul_output_0)\n  %/model.4/m.2/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.4/m.1/Add_output_0, %model.4.m.2.cv1.conv.weight, %model.4.m.2.cv1.conv.bias)\n  %/model.4/m.2/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.4/m.2/cv1/conv/Conv_output_0)\n  %/model.4/m.2/cv1/act/Mul_output_0 = Mul(%/model.4/m.2/cv1/conv/Conv_output_0, %/model.4/m.2/cv1/act/Sigmoid_output_0)\n  %/model.4/m.2/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.4/m.2/cv1/act/Mul_output_0, %model.4.m.2.cv2.conv.weight, %model.4.m.2.cv2.conv.bias)\n  %/model.4/m.2/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.4/m.2/cv2/conv/Conv_output_0)\n  %/model.4/m.2/cv2/act/Mul_output_0 = Mul(%/model.4/m.2/cv2/conv/Conv_output_0, %/model.4/m.2/cv2/act/Sigmoid_output_0)\n  %/model.4/m.2/Add_output_0 = Add(%/model.4/m.1/Add_output_0, %/model.4/m.2/cv2/act/Mul_output_0)\n  %/model.4/m.3/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.4/m.2/Add_output_0, %model.4.m.3.cv1.conv.weight, %model.4.m.3.cv1.conv.bias)\n  %/model.4/m.3/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.4/m.3/cv1/conv/Conv_output_0)\n  %/model.4/m.3/cv1/act/Mul_output_0 = Mul(%/model.4/m.3/cv1/conv/Conv_output_0, %/model.4/m.3/cv1/act/Sigmoid_output_0)\n  %/model.4/m.3/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.4/m.3/cv1/act/Mul_output_0, %model.4.m.3.cv2.conv.weight, %model.4.m.3.cv2.conv.bias)\n  %/model.4/m.3/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.4/m.3/cv2/conv/Conv_output_0)\n  %/model.4/m.3/cv2/act/Mul_output_0 = Mul(%/model.4/m.3/cv2/conv/Conv_output_0, %/model.4/m.3/cv2/act/Sigmoid_output_0)\n  %/model.4/m.3/Add_output_0 = Add(%/model.4/m.2/Add_output_0, %/model.4/m.3/cv2/act/Mul_output_0)\n  %/model.4/m.4/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.4/m.3/Add_output_0, %model.4.m.4.cv1.conv.weight, %model.4.m.4.cv1.conv.bias)\n  %/model.4/m.4/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.4/m.4/cv1/conv/Conv_output_0)\n  %/model.4/m.4/cv1/act/Mul_output_0 = Mul(%/model.4/m.4/cv1/conv/Conv_output_0, %/model.4/m.4/cv1/act/Sigmoid_output_0)\n  %/model.4/m.4/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.4/m.4/cv1/act/Mul_output_0, %model.4.m.4.cv2.conv.weight, %model.4.m.4.cv2.conv.bias)\n  %/model.4/m.4/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.4/m.4/cv2/conv/Conv_output_0)\n  %/model.4/m.4/cv2/act/Mul_output_0 = Mul(%/model.4/m.4/cv2/conv/Conv_output_0, %/model.4/m.4/cv2/act/Sigmoid_output_0)\n  %/model.4/m.4/Add_output_0 = Add(%/model.4/m.3/Add_output_0, %/model.4/m.4/cv2/act/Mul_output_0)\n  %/model.4/m.5/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.4/m.4/Add_output_0, %model.4.m.5.cv1.conv.weight, %model.4.m.5.cv1.conv.bias)\n  %/model.4/m.5/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.4/m.5/cv1/conv/Conv_output_0)\n  %/model.4/m.5/cv1/act/Mul_output_0 = Mul(%/model.4/m.5/cv1/conv/Conv_output_0, %/model.4/m.5/cv1/act/Sigmoid_output_0)\n  %/model.4/m.5/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.4/m.5/cv1/act/Mul_output_0, %model.4.m.5.cv2.conv.weight, %model.4.m.5.cv2.conv.bias)\n  %/model.4/m.5/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.4/m.5/cv2/conv/Conv_output_0)\n  %/model.4/m.5/cv2/act/Mul_output_0 = Mul(%/model.4/m.5/cv2/conv/Conv_output_0, %/model.4/m.5/cv2/act/Sigmoid_output_0)\n  %/model.4/m.5/Add_output_0 = Add(%/model.4/m.4/Add_output_0, %/model.4/m.5/cv2/act/Mul_output_0)\n  %/model.4/Concat_output_0 = Concat[axis = 1](%/model.4/Split_output_0, %/model.4/Split_output_1, %/model.4/m.0/Add_output_0, %/model.4/m.1/Add_output_0, %/model.4/m.2/Add_output_0, %/model.4/m.3/Add_output_0, %/model.4/m.4/Add_output_0, %/model.4/m.5/Add_output_0)\n  %/model.4/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.4/Concat_output_0, %model.4.cv2.conv.weight, %model.4.cv2.conv.bias)\n  %/model.4/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.4/cv2/conv/Conv_output_0)\n  %/model.4/cv2/act/Mul_output_0 = Mul(%/model.4/cv2/conv/Conv_output_0, %/model.4/cv2/act/Sigmoid_output_0)\n  %/model.5/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/model.4/cv2/act/Mul_output_0, %model.5.conv.weight, %model.5.conv.bias)\n  %/model.5/act/Sigmoid_output_0 = Sigmoid(%/model.5/conv/Conv_output_0)\n  %/model.5/act/Mul_output_0 = Mul(%/model.5/conv/Conv_output_0, %/model.5/act/Sigmoid_output_0)\n  %/model.6/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.5/act/Mul_output_0, %model.6.cv1.conv.weight, %model.6.cv1.conv.bias)\n  %/model.6/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.6/cv1/conv/Conv_output_0)\n  %/model.6/cv1/act/Mul_output_0 = Mul(%/model.6/cv1/conv/Conv_output_0, %/model.6/cv1/act/Sigmoid_output_0)\n  %/model.6/Split_output_0, %/model.6/Split_output_1 = Split[axis = 1](%/model.6/cv1/act/Mul_output_0, %onnx::Split_395)\n  %/model.6/m.0/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.6/Split_output_1, %model.6.m.0.cv1.conv.weight, %model.6.m.0.cv1.conv.bias)\n  %/model.6/m.0/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.6/m.0/cv1/conv/Conv_output_0)\n  %/model.6/m.0/cv1/act/Mul_output_0 = Mul(%/model.6/m.0/cv1/conv/Conv_output_0, %/model.6/m.0/cv1/act/Sigmoid_output_0)\n  %/model.6/m.0/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.6/m.0/cv1/act/Mul_output_0, %model.6.m.0.cv2.conv.weight, %model.6.m.0.cv2.conv.bias)\n  %/model.6/m.0/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.6/m.0/cv2/conv/Conv_output_0)\n  %/model.6/m.0/cv2/act/Mul_output_0 = Mul(%/model.6/m.0/cv2/conv/Conv_output_0, %/model.6/m.0/cv2/act/Sigmoid_output_0)\n  %/model.6/m.0/Add_output_0 = Add(%/model.6/Split_output_1, %/model.6/m.0/cv2/act/Mul_output_0)\n  %/model.6/m.1/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.6/m.0/Add_output_0, %model.6.m.1.cv1.conv.weight, %model.6.m.1.cv1.conv.bias)\n  %/model.6/m.1/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.6/m.1/cv1/conv/Conv_output_0)\n  %/model.6/m.1/cv1/act/Mul_output_0 = Mul(%/model.6/m.1/cv1/conv/Conv_output_0, %/model.6/m.1/cv1/act/Sigmoid_output_0)\n  %/model.6/m.1/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.6/m.1/cv1/act/Mul_output_0, %model.6.m.1.cv2.conv.weight, %model.6.m.1.cv2.conv.bias)\n  %/model.6/m.1/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.6/m.1/cv2/conv/Conv_output_0)\n  %/model.6/m.1/cv2/act/Mul_output_0 = Mul(%/model.6/m.1/cv2/conv/Conv_output_0, %/model.6/m.1/cv2/act/Sigmoid_output_0)\n  %/model.6/m.1/Add_output_0 = Add(%/model.6/m.0/Add_output_0, %/model.6/m.1/cv2/act/Mul_output_0)\n  %/model.6/m.2/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.6/m.1/Add_output_0, %model.6.m.2.cv1.conv.weight, %model.6.m.2.cv1.conv.bias)\n  %/model.6/m.2/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.6/m.2/cv1/conv/Conv_output_0)\n  %/model.6/m.2/cv1/act/Mul_output_0 = Mul(%/model.6/m.2/cv1/conv/Conv_output_0, %/model.6/m.2/cv1/act/Sigmoid_output_0)\n  %/model.6/m.2/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.6/m.2/cv1/act/Mul_output_0, %model.6.m.2.cv2.conv.weight, %model.6.m.2.cv2.conv.bias)\n  %/model.6/m.2/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.6/m.2/cv2/conv/Conv_output_0)\n  %/model.6/m.2/cv2/act/Mul_output_0 = Mul(%/model.6/m.2/cv2/conv/Conv_output_0, %/model.6/m.2/cv2/act/Sigmoid_output_0)\n  %/model.6/m.2/Add_output_0 = Add(%/model.6/m.1/Add_output_0, %/model.6/m.2/cv2/act/Mul_output_0)\n  %/model.6/m.3/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.6/m.2/Add_output_0, %model.6.m.3.cv1.conv.weight, %model.6.m.3.cv1.conv.bias)\n  %/model.6/m.3/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.6/m.3/cv1/conv/Conv_output_0)\n  %/model.6/m.3/cv1/act/Mul_output_0 = Mul(%/model.6/m.3/cv1/conv/Conv_output_0, %/model.6/m.3/cv1/act/Sigmoid_output_0)\n  %/model.6/m.3/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.6/m.3/cv1/act/Mul_output_0, %model.6.m.3.cv2.conv.weight, %model.6.m.3.cv2.conv.bias)\n  %/model.6/m.3/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.6/m.3/cv2/conv/Conv_output_0)\n  %/model.6/m.3/cv2/act/Mul_output_0 = Mul(%/model.6/m.3/cv2/conv/Conv_output_0, %/model.6/m.3/cv2/act/Sigmoid_output_0)\n  %/model.6/m.3/Add_output_0 = Add(%/model.6/m.2/Add_output_0, %/model.6/m.3/cv2/act/Mul_output_0)\n  %/model.6/m.4/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.6/m.3/Add_output_0, %model.6.m.4.cv1.conv.weight, %model.6.m.4.cv1.conv.bias)\n  %/model.6/m.4/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.6/m.4/cv1/conv/Conv_output_0)\n  %/model.6/m.4/cv1/act/Mul_output_0 = Mul(%/model.6/m.4/cv1/conv/Conv_output_0, %/model.6/m.4/cv1/act/Sigmoid_output_0)\n  %/model.6/m.4/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.6/m.4/cv1/act/Mul_output_0, %model.6.m.4.cv2.conv.weight, %model.6.m.4.cv2.conv.bias)\n  %/model.6/m.4/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.6/m.4/cv2/conv/Conv_output_0)\n  %/model.6/m.4/cv2/act/Mul_output_0 = Mul(%/model.6/m.4/cv2/conv/Conv_output_0, %/model.6/m.4/cv2/act/Sigmoid_output_0)\n  %/model.6/m.4/Add_output_0 = Add(%/model.6/m.3/Add_output_0, %/model.6/m.4/cv2/act/Mul_output_0)\n  %/model.6/m.5/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.6/m.4/Add_output_0, %model.6.m.5.cv1.conv.weight, %model.6.m.5.cv1.conv.bias)\n  %/model.6/m.5/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.6/m.5/cv1/conv/Conv_output_0)\n  %/model.6/m.5/cv1/act/Mul_output_0 = Mul(%/model.6/m.5/cv1/conv/Conv_output_0, %/model.6/m.5/cv1/act/Sigmoid_output_0)\n  %/model.6/m.5/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.6/m.5/cv1/act/Mul_output_0, %model.6.m.5.cv2.conv.weight, %model.6.m.5.cv2.conv.bias)\n  %/model.6/m.5/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.6/m.5/cv2/conv/Conv_output_0)\n  %/model.6/m.5/cv2/act/Mul_output_0 = Mul(%/model.6/m.5/cv2/conv/Conv_output_0, %/model.6/m.5/cv2/act/Sigmoid_output_0)\n  %/model.6/m.5/Add_output_0 = Add(%/model.6/m.4/Add_output_0, %/model.6/m.5/cv2/act/Mul_output_0)\n  %/model.6/Concat_output_0 = Concat[axis = 1](%/model.6/Split_output_0, %/model.6/Split_output_1, %/model.6/m.0/Add_output_0, %/model.6/m.1/Add_output_0, %/model.6/m.2/Add_output_0, %/model.6/m.3/Add_output_0, %/model.6/m.4/Add_output_0, %/model.6/m.5/Add_output_0)\n  %/model.6/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.6/Concat_output_0, %model.6.cv2.conv.weight, %model.6.cv2.conv.bias)\n  %/model.6/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.6/cv2/conv/Conv_output_0)\n  %/model.6/cv2/act/Mul_output_0 = Mul(%/model.6/cv2/conv/Conv_output_0, %/model.6/cv2/act/Sigmoid_output_0)\n  %/model.7/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/model.6/cv2/act/Mul_output_0, %model.7.conv.weight, %model.7.conv.bias)\n  %/model.7/act/Sigmoid_output_0 = Sigmoid(%/model.7/conv/Conv_output_0)\n  %/model.7/act/Mul_output_0 = Mul(%/model.7/conv/Conv_output_0, %/model.7/act/Sigmoid_output_0)\n  %/model.8/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.7/act/Mul_output_0, %model.8.cv1.conv.weight, %model.8.cv1.conv.bias)\n  %/model.8/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.8/cv1/conv/Conv_output_0)\n  %/model.8/cv1/act/Mul_output_0 = Mul(%/model.8/cv1/conv/Conv_output_0, %/model.8/cv1/act/Sigmoid_output_0)\n  %/model.8/Split_output_0, %/model.8/Split_output_1 = Split[axis = 1](%/model.8/cv1/act/Mul_output_0, %onnx::Split_395)\n  %/model.8/m.0/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.8/Split_output_1, %model.8.m.0.cv1.conv.weight, %model.8.m.0.cv1.conv.bias)\n  %/model.8/m.0/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.8/m.0/cv1/conv/Conv_output_0)\n  %/model.8/m.0/cv1/act/Mul_output_0 = Mul(%/model.8/m.0/cv1/conv/Conv_output_0, %/model.8/m.0/cv1/act/Sigmoid_output_0)\n  %/model.8/m.0/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.8/m.0/cv1/act/Mul_output_0, %model.8.m.0.cv2.conv.weight, %model.8.m.0.cv2.conv.bias)\n  %/model.8/m.0/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.8/m.0/cv2/conv/Conv_output_0)\n  %/model.8/m.0/cv2/act/Mul_output_0 = Mul(%/model.8/m.0/cv2/conv/Conv_output_0, %/model.8/m.0/cv2/act/Sigmoid_output_0)\n  %/model.8/m.0/Add_output_0 = Add(%/model.8/Split_output_1, %/model.8/m.0/cv2/act/Mul_output_0)\n  %/model.8/m.1/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.8/m.0/Add_output_0, %model.8.m.1.cv1.conv.weight, %model.8.m.1.cv1.conv.bias)\n  %/model.8/m.1/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.8/m.1/cv1/conv/Conv_output_0)\n  %/model.8/m.1/cv1/act/Mul_output_0 = Mul(%/model.8/m.1/cv1/conv/Conv_output_0, %/model.8/m.1/cv1/act/Sigmoid_output_0)\n  %/model.8/m.1/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.8/m.1/cv1/act/Mul_output_0, %model.8.m.1.cv2.conv.weight, %model.8.m.1.cv2.conv.bias)\n  %/model.8/m.1/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.8/m.1/cv2/conv/Conv_output_0)\n  %/model.8/m.1/cv2/act/Mul_output_0 = Mul(%/model.8/m.1/cv2/conv/Conv_output_0, %/model.8/m.1/cv2/act/Sigmoid_output_0)\n  %/model.8/m.1/Add_output_0 = Add(%/model.8/m.0/Add_output_0, %/model.8/m.1/cv2/act/Mul_output_0)\n  %/model.8/m.2/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.8/m.1/Add_output_0, %model.8.m.2.cv1.conv.weight, %model.8.m.2.cv1.conv.bias)\n  %/model.8/m.2/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.8/m.2/cv1/conv/Conv_output_0)\n  %/model.8/m.2/cv1/act/Mul_output_0 = Mul(%/model.8/m.2/cv1/conv/Conv_output_0, %/model.8/m.2/cv1/act/Sigmoid_output_0)\n  %/model.8/m.2/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.8/m.2/cv1/act/Mul_output_0, %model.8.m.2.cv2.conv.weight, %model.8.m.2.cv2.conv.bias)\n  %/model.8/m.2/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.8/m.2/cv2/conv/Conv_output_0)\n  %/model.8/m.2/cv2/act/Mul_output_0 = Mul(%/model.8/m.2/cv2/conv/Conv_output_0, %/model.8/m.2/cv2/act/Sigmoid_output_0)\n  %/model.8/m.2/Add_output_0 = Add(%/model.8/m.1/Add_output_0, %/model.8/m.2/cv2/act/Mul_output_0)\n  %/model.8/Concat_output_0 = Concat[axis = 1](%/model.8/Split_output_0, %/model.8/Split_output_1, %/model.8/m.0/Add_output_0, %/model.8/m.1/Add_output_0, %/model.8/m.2/Add_output_0)\n  %/model.8/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.8/Concat_output_0, %model.8.cv2.conv.weight, %model.8.cv2.conv.bias)\n  %/model.8/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.8/cv2/conv/Conv_output_0)\n  %/model.8/cv2/act/Mul_output_0 = Mul(%/model.8/cv2/conv/Conv_output_0, %/model.8/cv2/act/Sigmoid_output_0)\n  %/model.9/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/model.8/cv2/act/Mul_output_0, %model.9.conv.weight, %model.9.conv.bias)\n  %/model.9/act/Sigmoid_output_0 = Sigmoid(%/model.9/conv/Conv_output_0)\n  %/model.9/act/Mul_output_0 = Mul(%/model.9/conv/Conv_output_0, %/model.9/act/Sigmoid_output_0)\n  %/model.10/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.9/act/Mul_output_0, %model.10.cv1.conv.weight, %model.10.cv1.conv.bias)\n  %/model.10/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.10/cv1/conv/Conv_output_0)\n  %/model.10/cv1/act/Mul_output_0 = Mul(%/model.10/cv1/conv/Conv_output_0, %/model.10/cv1/act/Sigmoid_output_0)\n  %/model.10/Split_output_0, %/model.10/Split_output_1 = Split[axis = 1](%/model.10/cv1/act/Mul_output_0, %onnx::Split_395)\n  %/model.10/m.0/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.10/Split_output_1, %model.10.m.0.cv1.conv.weight, %model.10.m.0.cv1.conv.bias)\n  %/model.10/m.0/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.10/m.0/cv1/conv/Conv_output_0)\n  %/model.10/m.0/cv1/act/Mul_output_0 = Mul(%/model.10/m.0/cv1/conv/Conv_output_0, %/model.10/m.0/cv1/act/Sigmoid_output_0)\n  %/model.10/m.0/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.10/m.0/cv1/act/Mul_output_0, %model.10.m.0.cv2.conv.weight, %model.10.m.0.cv2.conv.bias)\n  %/model.10/m.0/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.10/m.0/cv2/conv/Conv_output_0)\n  %/model.10/m.0/cv2/act/Mul_output_0 = Mul(%/model.10/m.0/cv2/conv/Conv_output_0, %/model.10/m.0/cv2/act/Sigmoid_output_0)\n  %/model.10/m.0/Add_output_0 = Add(%/model.10/Split_output_1, %/model.10/m.0/cv2/act/Mul_output_0)\n  %/model.10/m.1/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.10/m.0/Add_output_0, %model.10.m.1.cv1.conv.weight, %model.10.m.1.cv1.conv.bias)\n  %/model.10/m.1/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.10/m.1/cv1/conv/Conv_output_0)\n  %/model.10/m.1/cv1/act/Mul_output_0 = Mul(%/model.10/m.1/cv1/conv/Conv_output_0, %/model.10/m.1/cv1/act/Sigmoid_output_0)\n  %/model.10/m.1/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.10/m.1/cv1/act/Mul_output_0, %model.10.m.1.cv2.conv.weight, %model.10.m.1.cv2.conv.bias)\n  %/model.10/m.1/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.10/m.1/cv2/conv/Conv_output_0)\n  %/model.10/m.1/cv2/act/Mul_output_0 = Mul(%/model.10/m.1/cv2/conv/Conv_output_0, %/model.10/m.1/cv2/act/Sigmoid_output_0)\n  %/model.10/m.1/Add_output_0 = Add(%/model.10/m.0/Add_output_0, %/model.10/m.1/cv2/act/Mul_output_0)\n  %/model.10/m.2/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.10/m.1/Add_output_0, %model.10.m.2.cv1.conv.weight, %model.10.m.2.cv1.conv.bias)\n  %/model.10/m.2/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.10/m.2/cv1/conv/Conv_output_0)\n  %/model.10/m.2/cv1/act/Mul_output_0 = Mul(%/model.10/m.2/cv1/conv/Conv_output_0, %/model.10/m.2/cv1/act/Sigmoid_output_0)\n  %/model.10/m.2/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.10/m.2/cv1/act/Mul_output_0, %model.10.m.2.cv2.conv.weight, %model.10.m.2.cv2.conv.bias)\n  %/model.10/m.2/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.10/m.2/cv2/conv/Conv_output_0)\n  %/model.10/m.2/cv2/act/Mul_output_0 = Mul(%/model.10/m.2/cv2/conv/Conv_output_0, %/model.10/m.2/cv2/act/Sigmoid_output_0)\n  %/model.10/m.2/Add_output_0 = Add(%/model.10/m.1/Add_output_0, %/model.10/m.2/cv2/act/Mul_output_0)\n  %/model.10/Concat_output_0 = Concat[axis = 1](%/model.10/Split_output_0, %/model.10/Split_output_1, %/model.10/m.0/Add_output_0, %/model.10/m.1/Add_output_0, %/model.10/m.2/Add_output_0)\n  %/model.10/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.10/Concat_output_0, %model.10.cv2.conv.weight, %model.10.cv2.conv.bias)\n  %/model.10/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.10/cv2/conv/Conv_output_0)\n  %/model.10/cv2/act/Mul_output_0 = Mul(%/model.10/cv2/conv/Conv_output_0, %/model.10/cv2/act/Sigmoid_output_0)\n  %/model.11/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.10/cv2/act/Mul_output_0, %model.11.cv1.conv.weight, %model.11.cv1.conv.bias)\n  %/model.11/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.11/cv1/conv/Conv_output_0)\n  %/model.11/cv1/act/Mul_output_0 = Mul(%/model.11/cv1/conv/Conv_output_0, %/model.11/cv1/act/Sigmoid_output_0)\n  %/model.11/m/MaxPool_output_0 = MaxPool[ceil_mode = 0, dilations = [1, 1], kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%/model.11/cv1/act/Mul_output_0)\n  %/model.11/m_1/MaxPool_output_0 = MaxPool[ceil_mode = 0, dilations = [1, 1], kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%/model.11/m/MaxPool_output_0)\n  %/model.11/m_2/MaxPool_output_0 = MaxPool[ceil_mode = 0, dilations = [1, 1], kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%/model.11/m_1/MaxPool_output_0)\n  %/model.11/Concat_output_0 = Concat[axis = 1](%/model.11/cv1/act/Mul_output_0, %/model.11/m/MaxPool_output_0, %/model.11/m_1/MaxPool_output_0, %/model.11/m_2/MaxPool_output_0)\n  %/model.11/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.11/Concat_output_0, %model.11.cv2.conv.weight, %model.11.cv2.conv.bias)\n  %/model.11/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.11/cv2/conv/Conv_output_0)\n  %/model.11/cv2/act/Mul_output_0 = Mul(%/model.11/cv2/conv/Conv_output_0, %/model.11/cv2/act/Sigmoid_output_0)\n  %/model.12/Resize_output_0 = Resize[coordinate_transformation_mode = 'asymmetric', cubic_coeff_a = -0.75, mode = 'nearest', nearest_mode = 'floor'](%/model.11/cv2/act/Mul_output_0, %, %/model.12/Constant_output_0)\n  %/model.13/Concat_output_0 = Concat[axis = 1](%/model.12/Resize_output_0, %/model.8/cv2/act/Mul_output_0)\n  %/model.14/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.13/Concat_output_0, %model.14.cv1.conv.weight, %model.14.cv1.conv.bias)\n  %/model.14/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.14/cv1/conv/Conv_output_0)\n  %/model.14/cv1/act/Mul_output_0 = Mul(%/model.14/cv1/conv/Conv_output_0, %/model.14/cv1/act/Sigmoid_output_0)\n  %/model.14/Slice_output_0 = Slice(%/model.14/cv1/act/Mul_output_0, %/model.14/Constant_1_output_0, %/model.14/Mul_output_0, %/model.14/Constant_output_0)\n  %/model.14/Slice_1_output_0 = Slice(%/model.14/cv1/act/Mul_output_0, %/model.14/Mul_output_0, %/model.14/Mul_1_output_0, %/model.14/Constant_output_0)\n  %/model.14/m/m.0/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.14/Slice_output_0, %model.14.m.0.cv1.conv.weight, %model.14.m.0.cv1.conv.bias)\n  %/model.14/m/m.0/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.14/m/m.0/cv1/conv/Conv_output_0)\n  %/model.14/m/m.0/cv1/act/Mul_output_0 = Mul(%/model.14/m/m.0/cv1/conv/Conv_output_0, %/model.14/m/m.0/cv1/act/Sigmoid_output_0)\n  %/model.14/m/m.0/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.14/m/m.0/cv1/act/Mul_output_0, %model.14.m.0.cv2.conv.weight, %model.14.m.0.cv2.conv.bias)\n  %/model.14/m/m.0/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.14/m/m.0/cv2/conv/Conv_output_0)\n  %/model.14/m/m.0/cv2/act/Mul_output_0 = Mul(%/model.14/m/m.0/cv2/conv/Conv_output_0, %/model.14/m/m.0/cv2/act/Sigmoid_output_0)\n  %/model.14/m/m.1/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.14/m/m.0/cv2/act/Mul_output_0, %model.14.m.1.cv1.conv.weight, %model.14.m.1.cv1.conv.bias)\n  %/model.14/m/m.1/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.14/m/m.1/cv1/conv/Conv_output_0)\n  %/model.14/m/m.1/cv1/act/Mul_output_0 = Mul(%/model.14/m/m.1/cv1/conv/Conv_output_0, %/model.14/m/m.1/cv1/act/Sigmoid_output_0)\n  %/model.14/m/m.1/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.14/m/m.1/cv1/act/Mul_output_0, %model.14.m.1.cv2.conv.weight, %model.14.m.1.cv2.conv.bias)\n  %/model.14/m/m.1/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.14/m/m.1/cv2/conv/Conv_output_0)\n  %/model.14/m/m.1/cv2/act/Mul_output_0 = Mul(%/model.14/m/m.1/cv2/conv/Conv_output_0, %/model.14/m/m.1/cv2/act/Sigmoid_output_0)\n  %/model.14/m/m.2/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.14/m/m.1/cv2/act/Mul_output_0, %model.14.m.2.cv1.conv.weight, %model.14.m.2.cv1.conv.bias)\n  %/model.14/m/m.2/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.14/m/m.2/cv1/conv/Conv_output_0)\n  %/model.14/m/m.2/cv1/act/Mul_output_0 = Mul(%/model.14/m/m.2/cv1/conv/Conv_output_0, %/model.14/m/m.2/cv1/act/Sigmoid_output_0)\n  %/model.14/m/m.2/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.14/m/m.2/cv1/act/Mul_output_0, %model.14.m.2.cv2.conv.weight, %model.14.m.2.cv2.conv.bias)\n  %/model.14/m/m.2/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.14/m/m.2/cv2/conv/Conv_output_0)\n  %/model.14/m/m.2/cv2/act/Mul_output_0 = Mul(%/model.14/m/m.2/cv2/conv/Conv_output_0, %/model.14/m/m.2/cv2/act/Sigmoid_output_0)\n  %/model.14/Concat_output_0 = Concat[axis = 1](%/model.14/m/m.2/cv2/act/Mul_output_0, %/model.14/Slice_1_output_0)\n  %/model.14/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.14/Concat_output_0, %model.14.cv2.conv.weight, %model.14.cv2.conv.bias)\n  %/model.14/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.14/cv2/conv/Conv_output_0)\n  %/model.14/cv2/act/Mul_output_0 = Mul(%/model.14/cv2/conv/Conv_output_0, %/model.14/cv2/act/Sigmoid_output_0)\n  %/model.15/Resize_output_0 = Resize[coordinate_transformation_mode = 'asymmetric', cubic_coeff_a = -0.75, mode = 'nearest', nearest_mode = 'floor'](%/model.14/cv2/act/Mul_output_0, %, %/model.12/Constant_output_0)\n  %/model.16/Concat_output_0 = Concat[axis = 1](%/model.15/Resize_output_0, %/model.6/cv2/act/Mul_output_0)\n  %/model.17/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.16/Concat_output_0, %model.17.cv1.conv.weight, %model.17.cv1.conv.bias)\n  %/model.17/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.17/cv1/conv/Conv_output_0)\n  %/model.17/cv1/act/Mul_output_0 = Mul(%/model.17/cv1/conv/Conv_output_0, %/model.17/cv1/act/Sigmoid_output_0)\n  %/model.17/Slice_output_0 = Slice(%/model.17/cv1/act/Mul_output_0, %/model.14/Constant_1_output_0, %/model.14/Mul_output_0, %/model.14/Constant_output_0)\n  %/model.17/Slice_1_output_0 = Slice(%/model.17/cv1/act/Mul_output_0, %/model.14/Mul_output_0, %/model.14/Mul_1_output_0, %/model.14/Constant_output_0)\n  %/model.17/m/m.0/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.17/Slice_output_0, %model.17.m.0.cv1.conv.weight, %model.17.m.0.cv1.conv.bias)\n  %/model.17/m/m.0/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.17/m/m.0/cv1/conv/Conv_output_0)\n  %/model.17/m/m.0/cv1/act/Mul_output_0 = Mul(%/model.17/m/m.0/cv1/conv/Conv_output_0, %/model.17/m/m.0/cv1/act/Sigmoid_output_0)\n  %/model.17/m/m.0/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.17/m/m.0/cv1/act/Mul_output_0, %model.17.m.0.cv2.conv.weight, %model.17.m.0.cv2.conv.bias)\n  %/model.17/m/m.0/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.17/m/m.0/cv2/conv/Conv_output_0)\n  %/model.17/m/m.0/cv2/act/Mul_output_0 = Mul(%/model.17/m/m.0/cv2/conv/Conv_output_0, %/model.17/m/m.0/cv2/act/Sigmoid_output_0)\n  %/model.17/m/m.1/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.17/m/m.0/cv2/act/Mul_output_0, %model.17.m.1.cv1.conv.weight, %model.17.m.1.cv1.conv.bias)\n  %/model.17/m/m.1/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.17/m/m.1/cv1/conv/Conv_output_0)\n  %/model.17/m/m.1/cv1/act/Mul_output_0 = Mul(%/model.17/m/m.1/cv1/conv/Conv_output_0, %/model.17/m/m.1/cv1/act/Sigmoid_output_0)\n  %/model.17/m/m.1/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.17/m/m.1/cv1/act/Mul_output_0, %model.17.m.1.cv2.conv.weight, %model.17.m.1.cv2.conv.bias)\n  %/model.17/m/m.1/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.17/m/m.1/cv2/conv/Conv_output_0)\n  %/model.17/m/m.1/cv2/act/Mul_output_0 = Mul(%/model.17/m/m.1/cv2/conv/Conv_output_0, %/model.17/m/m.1/cv2/act/Sigmoid_output_0)\n  %/model.17/m/m.2/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.17/m/m.1/cv2/act/Mul_output_0, %model.17.m.2.cv1.conv.weight, %model.17.m.2.cv1.conv.bias)\n  %/model.17/m/m.2/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.17/m/m.2/cv1/conv/Conv_output_0)\n  %/model.17/m/m.2/cv1/act/Mul_output_0 = Mul(%/model.17/m/m.2/cv1/conv/Conv_output_0, %/model.17/m/m.2/cv1/act/Sigmoid_output_0)\n  %/model.17/m/m.2/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.17/m/m.2/cv1/act/Mul_output_0, %model.17.m.2.cv2.conv.weight, %model.17.m.2.cv2.conv.bias)\n  %/model.17/m/m.2/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.17/m/m.2/cv2/conv/Conv_output_0)\n  %/model.17/m/m.2/cv2/act/Mul_output_0 = Mul(%/model.17/m/m.2/cv2/conv/Conv_output_0, %/model.17/m/m.2/cv2/act/Sigmoid_output_0)\n  %/model.17/Concat_output_0 = Concat[axis = 1](%/model.17/m/m.2/cv2/act/Mul_output_0, %/model.17/Slice_1_output_0)\n  %/model.17/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.17/Concat_output_0, %model.17.cv2.conv.weight, %model.17.cv2.conv.bias)\n  %/model.17/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.17/cv2/conv/Conv_output_0)\n  %/model.17/cv2/act/Mul_output_0 = Mul(%/model.17/cv2/conv/Conv_output_0, %/model.17/cv2/act/Sigmoid_output_0)\n  %/model.18/Resize_output_0 = Resize[coordinate_transformation_mode = 'asymmetric', cubic_coeff_a = -0.75, mode = 'nearest', nearest_mode = 'floor'](%/model.17/cv2/act/Mul_output_0, %, %/model.12/Constant_output_0)\n  %/model.19/Concat_output_0 = Concat[axis = 1](%/model.18/Resize_output_0, %/model.4/cv2/act/Mul_output_0)\n  %/model.20/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.19/Concat_output_0, %model.20.cv1.conv.weight, %model.20.cv1.conv.bias)\n  %/model.20/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.20/cv1/conv/Conv_output_0)\n  %/model.20/cv1/act/Mul_output_0 = Mul(%/model.20/cv1/conv/Conv_output_0, %/model.20/cv1/act/Sigmoid_output_0)\n  %/model.20/Slice_output_0 = Slice(%/model.20/cv1/act/Mul_output_0, %/model.14/Constant_1_output_0, %/model.20/Mul_output_0, %/model.14/Constant_output_0)\n  %/model.20/Slice_1_output_0 = Slice(%/model.20/cv1/act/Mul_output_0, %/model.20/Mul_output_0, %/model.14/Mul_output_0, %/model.14/Constant_output_0)\n  %/model.20/m/m.0/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.20/Slice_output_0, %model.20.m.0.cv1.conv.weight, %model.20.m.0.cv1.conv.bias)\n  %/model.20/m/m.0/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.20/m/m.0/cv1/conv/Conv_output_0)\n  %/model.20/m/m.0/cv1/act/Mul_output_0 = Mul(%/model.20/m/m.0/cv1/conv/Conv_output_0, %/model.20/m/m.0/cv1/act/Sigmoid_output_0)\n  %/model.20/m/m.0/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.20/m/m.0/cv1/act/Mul_output_0, %model.20.m.0.cv2.conv.weight, %model.20.m.0.cv2.conv.bias)\n  %/model.20/m/m.0/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.20/m/m.0/cv2/conv/Conv_output_0)\n  %/model.20/m/m.0/cv2/act/Mul_output_0 = Mul(%/model.20/m/m.0/cv2/conv/Conv_output_0, %/model.20/m/m.0/cv2/act/Sigmoid_output_0)\n  %/model.20/m/m.1/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.20/m/m.0/cv2/act/Mul_output_0, %model.20.m.1.cv1.conv.weight, %model.20.m.1.cv1.conv.bias)\n  %/model.20/m/m.1/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.20/m/m.1/cv1/conv/Conv_output_0)\n  %/model.20/m/m.1/cv1/act/Mul_output_0 = Mul(%/model.20/m/m.1/cv1/conv/Conv_output_0, %/model.20/m/m.1/cv1/act/Sigmoid_output_0)\n  %/model.20/m/m.1/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.20/m/m.1/cv1/act/Mul_output_0, %model.20.m.1.cv2.conv.weight, %model.20.m.1.cv2.conv.bias)\n  %/model.20/m/m.1/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.20/m/m.1/cv2/conv/Conv_output_0)\n  %/model.20/m/m.1/cv2/act/Mul_output_0 = Mul(%/model.20/m/m.1/cv2/conv/Conv_output_0, %/model.20/m/m.1/cv2/act/Sigmoid_output_0)\n  %/model.20/m/m.2/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.20/m/m.1/cv2/act/Mul_output_0, %model.20.m.2.cv1.conv.weight, %model.20.m.2.cv1.conv.bias)\n  %/model.20/m/m.2/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.20/m/m.2/cv1/conv/Conv_output_0)\n  %/model.20/m/m.2/cv1/act/Mul_output_0 = Mul(%/model.20/m/m.2/cv1/conv/Conv_output_0, %/model.20/m/m.2/cv1/act/Sigmoid_output_0)\n  %/model.20/m/m.2/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.20/m/m.2/cv1/act/Mul_output_0, %model.20.m.2.cv2.conv.weight, %model.20.m.2.cv2.conv.bias)\n  %/model.20/m/m.2/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.20/m/m.2/cv2/conv/Conv_output_0)\n  %/model.20/m/m.2/cv2/act/Mul_output_0 = Mul(%/model.20/m/m.2/cv2/conv/Conv_output_0, %/model.20/m/m.2/cv2/act/Sigmoid_output_0)\n  %/model.20/Concat_output_0 = Concat[axis = 1](%/model.20/m/m.2/cv2/act/Mul_output_0, %/model.20/Slice_1_output_0)\n  %/model.20/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.20/Concat_output_0, %model.20.cv2.conv.weight, %model.20.cv2.conv.bias)\n  %/model.20/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.20/cv2/conv/Conv_output_0)\n  %/model.20/cv2/act/Mul_output_0 = Mul(%/model.20/cv2/conv/Conv_output_0, %/model.20/cv2/act/Sigmoid_output_0)\n  %/model.21/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/model.20/cv2/act/Mul_output_0, %model.21.conv.weight, %model.21.conv.bias)\n  %/model.30/cv4.0/cv4.0.0/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.20/cv2/act/Mul_output_0, %model.30.cv4.0.0.conv.weight, %model.30.cv4.0.0.conv.bias)\n  %/model.30/cv2.0/cv2.0.0/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.20/cv2/act/Mul_output_0, %model.30.cv2.0.0.conv.weight, %model.30.cv2.0.0.conv.bias)\n  %/model.30/cv3.0/cv3.0.0/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.20/cv2/act/Mul_output_0, %model.30.cv3.0.0.conv.weight, %model.30.cv3.0.0.conv.bias)\n  %/model.21/act/Sigmoid_output_0 = Sigmoid(%/model.21/conv/Conv_output_0)\n  %/model.30/cv4.0/cv4.0.0/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv4.0/cv4.0.0/conv/Conv_output_0)\n  %/model.30/cv2.0/cv2.0.0/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv2.0/cv2.0.0/conv/Conv_output_0)\n  %/model.30/cv3.0/cv3.0.0/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv3.0/cv3.0.0/conv/Conv_output_0)\n  %/model.21/act/Mul_output_0 = Mul(%/model.21/conv/Conv_output_0, %/model.21/act/Sigmoid_output_0)\n  %/model.30/cv4.0/cv4.0.0/act/Mul_output_0 = Mul(%/model.30/cv4.0/cv4.0.0/conv/Conv_output_0, %/model.30/cv4.0/cv4.0.0/act/Sigmoid_output_0)\n  %/model.30/cv2.0/cv2.0.0/act/Mul_output_0 = Mul(%/model.30/cv2.0/cv2.0.0/conv/Conv_output_0, %/model.30/cv2.0/cv2.0.0/act/Sigmoid_output_0)\n  %/model.30/cv3.0/cv3.0.0/act/Mul_output_0 = Mul(%/model.30/cv3.0/cv3.0.0/conv/Conv_output_0, %/model.30/cv3.0/cv3.0.0/act/Sigmoid_output_0)\n  %/model.22/Concat_output_0 = Concat[axis = 1](%/model.21/act/Mul_output_0, %/model.17/cv2/act/Mul_output_0)\n  %/model.30/cv4.0/cv4.0.1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.30/cv4.0/cv4.0.0/act/Mul_output_0, %model.30.cv4.0.1.conv.weight, %model.30.cv4.0.1.conv.bias)\n  %/model.30/cv2.0/cv2.0.1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.30/cv2.0/cv2.0.0/act/Mul_output_0, %model.30.cv2.0.1.conv.weight, %model.30.cv2.0.1.conv.bias)\n  %/model.30/cv3.0/cv3.0.1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.30/cv3.0/cv3.0.0/act/Mul_output_0, %model.30.cv3.0.1.conv.weight, %model.30.cv3.0.1.conv.bias)\n  %/model.23/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.22/Concat_output_0, %model.23.cv1.conv.weight, %model.23.cv1.conv.bias)\n  %/model.30/cv4.0/cv4.0.1/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv4.0/cv4.0.1/conv/Conv_output_0)\n  %/model.30/cv2.0/cv2.0.1/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv2.0/cv2.0.1/conv/Conv_output_0)\n  %/model.30/cv3.0/cv3.0.1/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv3.0/cv3.0.1/conv/Conv_output_0)\n  %/model.23/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.23/cv1/conv/Conv_output_0)\n  %/model.30/cv4.0/cv4.0.1/act/Mul_output_0 = Mul(%/model.30/cv4.0/cv4.0.1/conv/Conv_output_0, %/model.30/cv4.0/cv4.0.1/act/Sigmoid_output_0)\n  %/model.30/cv2.0/cv2.0.1/act/Mul_output_0 = Mul(%/model.30/cv2.0/cv2.0.1/conv/Conv_output_0, %/model.30/cv2.0/cv2.0.1/act/Sigmoid_output_0)\n  %/model.30/cv3.0/cv3.0.1/act/Mul_output_0 = Mul(%/model.30/cv3.0/cv3.0.1/conv/Conv_output_0, %/model.30/cv3.0/cv3.0.1/act/Sigmoid_output_0)\n  %/model.23/cv1/act/Mul_output_0 = Mul(%/model.23/cv1/conv/Conv_output_0, %/model.23/cv1/act/Sigmoid_output_0)\n  %/model.30/cv4.0/cv4.0.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.30/cv4.0/cv4.0.1/act/Mul_output_0, %model.30.cv4.0.2.weight, %model.30.cv4.0.2.bias)\n  %/model.30/cv2.0/cv2.0.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.30/cv2.0/cv2.0.1/act/Mul_output_0, %model.30.cv2.0.2.weight, %model.30.cv2.0.2.bias)\n  %/model.30/cv3.0/cv3.0.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.30/cv3.0/cv3.0.1/act/Mul_output_0, %model.30.cv3.0.2.weight, %model.30.cv3.0.2.bias)\n  %/model.30/Reshape_output_0 = Reshape[allowzero = 0](%/model.30/cv4.0/cv4.0.2/Conv_output_0, %/model.30/Constant_output_0)\n  %/model.30/Concat_1_output_0 = Concat[axis = 1](%/model.30/cv2.0/cv2.0.2/Conv_output_0, %/model.30/cv3.0/cv3.0.2/Conv_output_0)\n  %/model.23/Slice_output_0 = Slice(%/model.23/cv1/act/Mul_output_0, %/model.14/Constant_1_output_0, %/model.14/Mul_output_0, %/model.14/Constant_output_0)\n  %/model.23/Slice_1_output_0 = Slice(%/model.23/cv1/act/Mul_output_0, %/model.14/Mul_output_0, %/model.14/Mul_1_output_0, %/model.14/Constant_output_0)\n  %/model.30/Reshape_4_output_0 = Reshape[allowzero = 0](%/model.30/Concat_1_output_0, %/model.30/Constant_5_output_0)\n  %/model.23/m/m.0/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.23/Slice_output_0, %model.23.m.0.cv1.conv.weight, %model.23.m.0.cv1.conv.bias)\n  %/model.23/m/m.0/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.23/m/m.0/cv1/conv/Conv_output_0)\n  %/model.23/m/m.0/cv1/act/Mul_output_0 = Mul(%/model.23/m/m.0/cv1/conv/Conv_output_0, %/model.23/m/m.0/cv1/act/Sigmoid_output_0)\n  %/model.23/m/m.0/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.23/m/m.0/cv1/act/Mul_output_0, %model.23.m.0.cv2.conv.weight, %model.23.m.0.cv2.conv.bias)\n  %/model.23/m/m.0/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.23/m/m.0/cv2/conv/Conv_output_0)\n  %/model.23/m/m.0/cv2/act/Mul_output_0 = Mul(%/model.23/m/m.0/cv2/conv/Conv_output_0, %/model.23/m/m.0/cv2/act/Sigmoid_output_0)\n  %/model.23/m/m.1/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.23/m/m.0/cv2/act/Mul_output_0, %model.23.m.1.cv1.conv.weight, %model.23.m.1.cv1.conv.bias)\n  %/model.23/m/m.1/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.23/m/m.1/cv1/conv/Conv_output_0)\n  %/model.23/m/m.1/cv1/act/Mul_output_0 = Mul(%/model.23/m/m.1/cv1/conv/Conv_output_0, %/model.23/m/m.1/cv1/act/Sigmoid_output_0)\n  %/model.23/m/m.1/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.23/m/m.1/cv1/act/Mul_output_0, %model.23.m.1.cv2.conv.weight, %model.23.m.1.cv2.conv.bias)\n  %/model.23/m/m.1/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.23/m/m.1/cv2/conv/Conv_output_0)\n  %/model.23/m/m.1/cv2/act/Mul_output_0 = Mul(%/model.23/m/m.1/cv2/conv/Conv_output_0, %/model.23/m/m.1/cv2/act/Sigmoid_output_0)\n  %/model.23/m/m.2/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.23/m/m.1/cv2/act/Mul_output_0, %model.23.m.2.cv1.conv.weight, %model.23.m.2.cv1.conv.bias)\n  %/model.23/m/m.2/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.23/m/m.2/cv1/conv/Conv_output_0)\n  %/model.23/m/m.2/cv1/act/Mul_output_0 = Mul(%/model.23/m/m.2/cv1/conv/Conv_output_0, %/model.23/m/m.2/cv1/act/Sigmoid_output_0)\n  %/model.23/m/m.2/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.23/m/m.2/cv1/act/Mul_output_0, %model.23.m.2.cv2.conv.weight, %model.23.m.2.cv2.conv.bias)\n  %/model.23/m/m.2/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.23/m/m.2/cv2/conv/Conv_output_0)\n  %/model.23/m/m.2/cv2/act/Mul_output_0 = Mul(%/model.23/m/m.2/cv2/conv/Conv_output_0, %/model.23/m/m.2/cv2/act/Sigmoid_output_0)\n  %/model.23/Concat_output_0 = Concat[axis = 1](%/model.23/m/m.2/cv2/act/Mul_output_0, %/model.23/Slice_1_output_0)\n  %/model.23/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.23/Concat_output_0, %model.23.cv2.conv.weight, %model.23.cv2.conv.bias)\n  %/model.23/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.23/cv2/conv/Conv_output_0)\n  %/model.23/cv2/act/Mul_output_0 = Mul(%/model.23/cv2/conv/Conv_output_0, %/model.23/cv2/act/Sigmoid_output_0)\n  %/model.24/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/model.23/cv2/act/Mul_output_0, %model.24.conv.weight, %model.24.conv.bias)\n  %/model.30/cv4.1/cv4.1.0/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.23/cv2/act/Mul_output_0, %model.30.cv4.1.0.conv.weight, %model.30.cv4.1.0.conv.bias)\n  %/model.30/cv2.1/cv2.1.0/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.23/cv2/act/Mul_output_0, %model.30.cv2.1.0.conv.weight, %model.30.cv2.1.0.conv.bias)\n  %/model.30/cv3.1/cv3.1.0/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.23/cv2/act/Mul_output_0, %model.30.cv3.1.0.conv.weight, %model.30.cv3.1.0.conv.bias)\n  %/model.24/act/Sigmoid_output_0 = Sigmoid(%/model.24/conv/Conv_output_0)\n  %/model.30/cv4.1/cv4.1.0/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv4.1/cv4.1.0/conv/Conv_output_0)\n  %/model.30/cv2.1/cv2.1.0/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv2.1/cv2.1.0/conv/Conv_output_0)\n  %/model.30/cv3.1/cv3.1.0/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv3.1/cv3.1.0/conv/Conv_output_0)\n  %/model.24/act/Mul_output_0 = Mul(%/model.24/conv/Conv_output_0, %/model.24/act/Sigmoid_output_0)\n  %/model.30/cv4.1/cv4.1.0/act/Mul_output_0 = Mul(%/model.30/cv4.1/cv4.1.0/conv/Conv_output_0, %/model.30/cv4.1/cv4.1.0/act/Sigmoid_output_0)\n  %/model.30/cv2.1/cv2.1.0/act/Mul_output_0 = Mul(%/model.30/cv2.1/cv2.1.0/conv/Conv_output_0, %/model.30/cv2.1/cv2.1.0/act/Sigmoid_output_0)\n  %/model.30/cv3.1/cv3.1.0/act/Mul_output_0 = Mul(%/model.30/cv3.1/cv3.1.0/conv/Conv_output_0, %/model.30/cv3.1/cv3.1.0/act/Sigmoid_output_0)\n  %/model.25/Concat_output_0 = Concat[axis = 1](%/model.24/act/Mul_output_0, %/model.14/cv2/act/Mul_output_0)\n  %/model.30/cv4.1/cv4.1.1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.30/cv4.1/cv4.1.0/act/Mul_output_0, %model.30.cv4.1.1.conv.weight, %model.30.cv4.1.1.conv.bias)\n  %/model.30/cv2.1/cv2.1.1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.30/cv2.1/cv2.1.0/act/Mul_output_0, %model.30.cv2.1.1.conv.weight, %model.30.cv2.1.1.conv.bias)\n  %/model.30/cv3.1/cv3.1.1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.30/cv3.1/cv3.1.0/act/Mul_output_0, %model.30.cv3.1.1.conv.weight, %model.30.cv3.1.1.conv.bias)\n  %/model.26/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.25/Concat_output_0, %model.26.cv1.conv.weight, %model.26.cv1.conv.bias)\n  %/model.30/cv4.1/cv4.1.1/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv4.1/cv4.1.1/conv/Conv_output_0)\n  %/model.30/cv2.1/cv2.1.1/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv2.1/cv2.1.1/conv/Conv_output_0)\n  %/model.30/cv3.1/cv3.1.1/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv3.1/cv3.1.1/conv/Conv_output_0)\n  %/model.26/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.26/cv1/conv/Conv_output_0)\n  %/model.30/cv4.1/cv4.1.1/act/Mul_output_0 = Mul(%/model.30/cv4.1/cv4.1.1/conv/Conv_output_0, %/model.30/cv4.1/cv4.1.1/act/Sigmoid_output_0)\n  %/model.30/cv2.1/cv2.1.1/act/Mul_output_0 = Mul(%/model.30/cv2.1/cv2.1.1/conv/Conv_output_0, %/model.30/cv2.1/cv2.1.1/act/Sigmoid_output_0)\n  %/model.30/cv3.1/cv3.1.1/act/Mul_output_0 = Mul(%/model.30/cv3.1/cv3.1.1/conv/Conv_output_0, %/model.30/cv3.1/cv3.1.1/act/Sigmoid_output_0)\n  %/model.26/cv1/act/Mul_output_0 = Mul(%/model.26/cv1/conv/Conv_output_0, %/model.26/cv1/act/Sigmoid_output_0)\n  %/model.30/cv4.1/cv4.1.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.30/cv4.1/cv4.1.1/act/Mul_output_0, %model.30.cv4.1.2.weight, %model.30.cv4.1.2.bias)\n  %/model.30/cv2.1/cv2.1.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.30/cv2.1/cv2.1.1/act/Mul_output_0, %model.30.cv2.1.2.weight, %model.30.cv2.1.2.bias)\n  %/model.30/cv3.1/cv3.1.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.30/cv3.1/cv3.1.1/act/Mul_output_0, %model.30.cv3.1.2.weight, %model.30.cv3.1.2.bias)\n  %/model.30/Reshape_1_output_0 = Reshape[allowzero = 0](%/model.30/cv4.1/cv4.1.2/Conv_output_0, %/model.30/Constant_output_0)\n  %/model.30/Concat_2_output_0 = Concat[axis = 1](%/model.30/cv2.1/cv2.1.2/Conv_output_0, %/model.30/cv3.1/cv3.1.2/Conv_output_0)\n  %/model.26/Slice_output_0 = Slice(%/model.26/cv1/act/Mul_output_0, %/model.14/Constant_1_output_0, %/model.14/Mul_output_0, %/model.14/Constant_output_0)\n  %/model.26/Slice_1_output_0 = Slice(%/model.26/cv1/act/Mul_output_0, %/model.14/Mul_output_0, %/model.14/Mul_1_output_0, %/model.14/Constant_output_0)\n  %/model.30/Reshape_5_output_0 = Reshape[allowzero = 0](%/model.30/Concat_2_output_0, %/model.30/Constant_5_output_0)\n  %/model.26/m/m.0/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.26/Slice_output_0, %model.26.m.0.cv1.conv.weight, %model.26.m.0.cv1.conv.bias)\n  %/model.26/m/m.0/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.26/m/m.0/cv1/conv/Conv_output_0)\n  %/model.26/m/m.0/cv1/act/Mul_output_0 = Mul(%/model.26/m/m.0/cv1/conv/Conv_output_0, %/model.26/m/m.0/cv1/act/Sigmoid_output_0)\n  %/model.26/m/m.0/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.26/m/m.0/cv1/act/Mul_output_0, %model.26.m.0.cv2.conv.weight, %model.26.m.0.cv2.conv.bias)\n  %/model.26/m/m.0/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.26/m/m.0/cv2/conv/Conv_output_0)\n  %/model.26/m/m.0/cv2/act/Mul_output_0 = Mul(%/model.26/m/m.0/cv2/conv/Conv_output_0, %/model.26/m/m.0/cv2/act/Sigmoid_output_0)\n  %/model.26/m/m.1/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.26/m/m.0/cv2/act/Mul_output_0, %model.26.m.1.cv1.conv.weight, %model.26.m.1.cv1.conv.bias)\n  %/model.26/m/m.1/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.26/m/m.1/cv1/conv/Conv_output_0)\n  %/model.26/m/m.1/cv1/act/Mul_output_0 = Mul(%/model.26/m/m.1/cv1/conv/Conv_output_0, %/model.26/m/m.1/cv1/act/Sigmoid_output_0)\n  %/model.26/m/m.1/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.26/m/m.1/cv1/act/Mul_output_0, %model.26.m.1.cv2.conv.weight, %model.26.m.1.cv2.conv.bias)\n  %/model.26/m/m.1/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.26/m/m.1/cv2/conv/Conv_output_0)\n  %/model.26/m/m.1/cv2/act/Mul_output_0 = Mul(%/model.26/m/m.1/cv2/conv/Conv_output_0, %/model.26/m/m.1/cv2/act/Sigmoid_output_0)\n  %/model.26/m/m.2/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.26/m/m.1/cv2/act/Mul_output_0, %model.26.m.2.cv1.conv.weight, %model.26.m.2.cv1.conv.bias)\n  %/model.26/m/m.2/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.26/m/m.2/cv1/conv/Conv_output_0)\n  %/model.26/m/m.2/cv1/act/Mul_output_0 = Mul(%/model.26/m/m.2/cv1/conv/Conv_output_0, %/model.26/m/m.2/cv1/act/Sigmoid_output_0)\n  %/model.26/m/m.2/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.26/m/m.2/cv1/act/Mul_output_0, %model.26.m.2.cv2.conv.weight, %model.26.m.2.cv2.conv.bias)\n  %/model.26/m/m.2/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.26/m/m.2/cv2/conv/Conv_output_0)\n  %/model.26/m/m.2/cv2/act/Mul_output_0 = Mul(%/model.26/m/m.2/cv2/conv/Conv_output_0, %/model.26/m/m.2/cv2/act/Sigmoid_output_0)\n  %/model.26/Concat_output_0 = Concat[axis = 1](%/model.26/m/m.2/cv2/act/Mul_output_0, %/model.26/Slice_1_output_0)\n  %/model.26/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.26/Concat_output_0, %model.26.cv2.conv.weight, %model.26.cv2.conv.bias)\n  %/model.26/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.26/cv2/conv/Conv_output_0)\n  %/model.26/cv2/act/Mul_output_0 = Mul(%/model.26/cv2/conv/Conv_output_0, %/model.26/cv2/act/Sigmoid_output_0)\n  %/model.27/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/model.26/cv2/act/Mul_output_0, %model.27.conv.weight, %model.27.conv.bias)\n  %/model.30/cv4.2/cv4.2.0/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.26/cv2/act/Mul_output_0, %model.30.cv4.2.0.conv.weight, %model.30.cv4.2.0.conv.bias)\n  %/model.30/cv2.2/cv2.2.0/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.26/cv2/act/Mul_output_0, %model.30.cv2.2.0.conv.weight, %model.30.cv2.2.0.conv.bias)\n  %/model.30/cv3.2/cv3.2.0/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.26/cv2/act/Mul_output_0, %model.30.cv3.2.0.conv.weight, %model.30.cv3.2.0.conv.bias)\n  %/model.27/act/Sigmoid_output_0 = Sigmoid(%/model.27/conv/Conv_output_0)\n  %/model.30/cv4.2/cv4.2.0/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv4.2/cv4.2.0/conv/Conv_output_0)\n  %/model.30/cv2.2/cv2.2.0/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv2.2/cv2.2.0/conv/Conv_output_0)\n  %/model.30/cv3.2/cv3.2.0/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv3.2/cv3.2.0/conv/Conv_output_0)\n  %/model.27/act/Mul_output_0 = Mul(%/model.27/conv/Conv_output_0, %/model.27/act/Sigmoid_output_0)\n  %/model.30/cv4.2/cv4.2.0/act/Mul_output_0 = Mul(%/model.30/cv4.2/cv4.2.0/conv/Conv_output_0, %/model.30/cv4.2/cv4.2.0/act/Sigmoid_output_0)\n  %/model.30/cv2.2/cv2.2.0/act/Mul_output_0 = Mul(%/model.30/cv2.2/cv2.2.0/conv/Conv_output_0, %/model.30/cv2.2/cv2.2.0/act/Sigmoid_output_0)\n  %/model.30/cv3.2/cv3.2.0/act/Mul_output_0 = Mul(%/model.30/cv3.2/cv3.2.0/conv/Conv_output_0, %/model.30/cv3.2/cv3.2.0/act/Sigmoid_output_0)\n  %/model.28/Concat_output_0 = Concat[axis = 1](%/model.27/act/Mul_output_0, %/model.11/cv2/act/Mul_output_0)\n  %/model.30/cv4.2/cv4.2.1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.30/cv4.2/cv4.2.0/act/Mul_output_0, %model.30.cv4.2.1.conv.weight, %model.30.cv4.2.1.conv.bias)\n  %/model.30/cv2.2/cv2.2.1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.30/cv2.2/cv2.2.0/act/Mul_output_0, %model.30.cv2.2.1.conv.weight, %model.30.cv2.2.1.conv.bias)\n  %/model.30/cv3.2/cv3.2.1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.30/cv3.2/cv3.2.0/act/Mul_output_0, %model.30.cv3.2.1.conv.weight, %model.30.cv3.2.1.conv.bias)\n  %/model.29/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.28/Concat_output_0, %model.29.cv1.conv.weight, %model.29.cv1.conv.bias)\n  %/model.30/cv4.2/cv4.2.1/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv4.2/cv4.2.1/conv/Conv_output_0)\n  %/model.30/cv2.2/cv2.2.1/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv2.2/cv2.2.1/conv/Conv_output_0)\n  %/model.30/cv3.2/cv3.2.1/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv3.2/cv3.2.1/conv/Conv_output_0)\n  %/model.29/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.29/cv1/conv/Conv_output_0)\n  %/model.30/cv4.2/cv4.2.1/act/Mul_output_0 = Mul(%/model.30/cv4.2/cv4.2.1/conv/Conv_output_0, %/model.30/cv4.2/cv4.2.1/act/Sigmoid_output_0)\n  %/model.30/cv2.2/cv2.2.1/act/Mul_output_0 = Mul(%/model.30/cv2.2/cv2.2.1/conv/Conv_output_0, %/model.30/cv2.2/cv2.2.1/act/Sigmoid_output_0)\n  %/model.30/cv3.2/cv3.2.1/act/Mul_output_0 = Mul(%/model.30/cv3.2/cv3.2.1/conv/Conv_output_0, %/model.30/cv3.2/cv3.2.1/act/Sigmoid_output_0)\n  %/model.29/cv1/act/Mul_output_0 = Mul(%/model.29/cv1/conv/Conv_output_0, %/model.29/cv1/act/Sigmoid_output_0)\n  %/model.30/cv4.2/cv4.2.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.30/cv4.2/cv4.2.1/act/Mul_output_0, %model.30.cv4.2.2.weight, %model.30.cv4.2.2.bias)\n  %/model.30/cv2.2/cv2.2.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.30/cv2.2/cv2.2.1/act/Mul_output_0, %model.30.cv2.2.2.weight, %model.30.cv2.2.2.bias)\n  %/model.30/cv3.2/cv3.2.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.30/cv3.2/cv3.2.1/act/Mul_output_0, %model.30.cv3.2.2.weight, %model.30.cv3.2.2.bias)\n  %/model.30/Reshape_2_output_0 = Reshape[allowzero = 0](%/model.30/cv4.2/cv4.2.2/Conv_output_0, %/model.30/Constant_output_0)\n  %/model.30/Concat_3_output_0 = Concat[axis = 1](%/model.30/cv2.2/cv2.2.2/Conv_output_0, %/model.30/cv3.2/cv3.2.2/Conv_output_0)\n  %/model.29/Slice_output_0 = Slice(%/model.29/cv1/act/Mul_output_0, %/model.14/Constant_1_output_0, %/model.14/Mul_output_0, %/model.14/Constant_output_0)\n  %/model.29/Slice_1_output_0 = Slice(%/model.29/cv1/act/Mul_output_0, %/model.14/Mul_output_0, %/model.14/Mul_1_output_0, %/model.14/Constant_output_0)\n  %/model.30/Reshape_6_output_0 = Reshape[allowzero = 0](%/model.30/Concat_3_output_0, %/model.30/Constant_5_output_0)\n  %/model.29/m/m.0/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.29/Slice_output_0, %model.29.m.0.cv1.conv.weight, %model.29.m.0.cv1.conv.bias)\n  %/model.29/m/m.0/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.29/m/m.0/cv1/conv/Conv_output_0)\n  %/model.29/m/m.0/cv1/act/Mul_output_0 = Mul(%/model.29/m/m.0/cv1/conv/Conv_output_0, %/model.29/m/m.0/cv1/act/Sigmoid_output_0)\n  %/model.29/m/m.0/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.29/m/m.0/cv1/act/Mul_output_0, %model.29.m.0.cv2.conv.weight, %model.29.m.0.cv2.conv.bias)\n  %/model.29/m/m.0/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.29/m/m.0/cv2/conv/Conv_output_0)\n  %/model.29/m/m.0/cv2/act/Mul_output_0 = Mul(%/model.29/m/m.0/cv2/conv/Conv_output_0, %/model.29/m/m.0/cv2/act/Sigmoid_output_0)\n  %/model.29/m/m.1/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.29/m/m.0/cv2/act/Mul_output_0, %model.29.m.1.cv1.conv.weight, %model.29.m.1.cv1.conv.bias)\n  %/model.29/m/m.1/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.29/m/m.1/cv1/conv/Conv_output_0)\n  %/model.29/m/m.1/cv1/act/Mul_output_0 = Mul(%/model.29/m/m.1/cv1/conv/Conv_output_0, %/model.29/m/m.1/cv1/act/Sigmoid_output_0)\n  %/model.29/m/m.1/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.29/m/m.1/cv1/act/Mul_output_0, %model.29.m.1.cv2.conv.weight, %model.29.m.1.cv2.conv.bias)\n  %/model.29/m/m.1/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.29/m/m.1/cv2/conv/Conv_output_0)\n  %/model.29/m/m.1/cv2/act/Mul_output_0 = Mul(%/model.29/m/m.1/cv2/conv/Conv_output_0, %/model.29/m/m.1/cv2/act/Sigmoid_output_0)\n  %/model.29/m/m.2/cv1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.29/m/m.1/cv2/act/Mul_output_0, %model.29.m.2.cv1.conv.weight, %model.29.m.2.cv1.conv.bias)\n  %/model.29/m/m.2/cv1/act/Sigmoid_output_0 = Sigmoid(%/model.29/m/m.2/cv1/conv/Conv_output_0)\n  %/model.29/m/m.2/cv1/act/Mul_output_0 = Mul(%/model.29/m/m.2/cv1/conv/Conv_output_0, %/model.29/m/m.2/cv1/act/Sigmoid_output_0)\n  %/model.29/m/m.2/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.29/m/m.2/cv1/act/Mul_output_0, %model.29.m.2.cv2.conv.weight, %model.29.m.2.cv2.conv.bias)\n  %/model.29/m/m.2/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.29/m/m.2/cv2/conv/Conv_output_0)\n  %/model.29/m/m.2/cv2/act/Mul_output_0 = Mul(%/model.29/m/m.2/cv2/conv/Conv_output_0, %/model.29/m/m.2/cv2/act/Sigmoid_output_0)\n  %/model.29/Concat_output_0 = Concat[axis = 1](%/model.29/m/m.2/cv2/act/Mul_output_0, %/model.29/Slice_1_output_0)\n  %/model.29/cv2/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.29/Concat_output_0, %model.29.cv2.conv.weight, %model.29.cv2.conv.bias)\n  %/model.29/cv2/act/Sigmoid_output_0 = Sigmoid(%/model.29/cv2/conv/Conv_output_0)\n  %/model.29/cv2/act/Mul_output_0 = Mul(%/model.29/cv2/conv/Conv_output_0, %/model.29/cv2/act/Sigmoid_output_0)\n  %/model.30/cv4.3/cv4.3.0/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.29/cv2/act/Mul_output_0, %model.30.cv4.3.0.conv.weight, %model.30.cv4.3.0.conv.bias)\n  %/model.30/cv2.3/cv2.3.0/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.29/cv2/act/Mul_output_0, %model.30.cv2.3.0.conv.weight, %model.30.cv2.3.0.conv.bias)\n  %/model.30/cv3.3/cv3.3.0/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.29/cv2/act/Mul_output_0, %model.30.cv3.3.0.conv.weight, %model.30.cv3.3.0.conv.bias)\n  %/model.30/cv4.3/cv4.3.0/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv4.3/cv4.3.0/conv/Conv_output_0)\n  %/model.30/cv2.3/cv2.3.0/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv2.3/cv2.3.0/conv/Conv_output_0)\n  %/model.30/cv3.3/cv3.3.0/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv3.3/cv3.3.0/conv/Conv_output_0)\n  %/model.30/cv4.3/cv4.3.0/act/Mul_output_0 = Mul(%/model.30/cv4.3/cv4.3.0/conv/Conv_output_0, %/model.30/cv4.3/cv4.3.0/act/Sigmoid_output_0)\n  %/model.30/cv2.3/cv2.3.0/act/Mul_output_0 = Mul(%/model.30/cv2.3/cv2.3.0/conv/Conv_output_0, %/model.30/cv2.3/cv2.3.0/act/Sigmoid_output_0)\n  %/model.30/cv3.3/cv3.3.0/act/Mul_output_0 = Mul(%/model.30/cv3.3/cv3.3.0/conv/Conv_output_0, %/model.30/cv3.3/cv3.3.0/act/Sigmoid_output_0)\n  %/model.30/cv4.3/cv4.3.1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.30/cv4.3/cv4.3.0/act/Mul_output_0, %model.30.cv4.3.1.conv.weight, %model.30.cv4.3.1.conv.bias)\n  %/model.30/cv2.3/cv2.3.1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.30/cv2.3/cv2.3.0/act/Mul_output_0, %model.30.cv2.3.1.conv.weight, %model.30.cv2.3.1.conv.bias)\n  %/model.30/cv3.3/cv3.3.1/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/model.30/cv3.3/cv3.3.0/act/Mul_output_0, %model.30.cv3.3.1.conv.weight, %model.30.cv3.3.1.conv.bias)\n  %/model.30/cv4.3/cv4.3.1/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv4.3/cv4.3.1/conv/Conv_output_0)\n  %/model.30/cv2.3/cv2.3.1/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv2.3/cv2.3.1/conv/Conv_output_0)\n  %/model.30/cv3.3/cv3.3.1/act/Sigmoid_output_0 = Sigmoid(%/model.30/cv3.3/cv3.3.1/conv/Conv_output_0)\n  %/model.30/cv4.3/cv4.3.1/act/Mul_output_0 = Mul(%/model.30/cv4.3/cv4.3.1/conv/Conv_output_0, %/model.30/cv4.3/cv4.3.1/act/Sigmoid_output_0)\n  %/model.30/cv2.3/cv2.3.1/act/Mul_output_0 = Mul(%/model.30/cv2.3/cv2.3.1/conv/Conv_output_0, %/model.30/cv2.3/cv2.3.1/act/Sigmoid_output_0)\n  %/model.30/cv3.3/cv3.3.1/act/Mul_output_0 = Mul(%/model.30/cv3.3/cv3.3.1/conv/Conv_output_0, %/model.30/cv3.3/cv3.3.1/act/Sigmoid_output_0)\n  %/model.30/cv4.3/cv4.3.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.30/cv4.3/cv4.3.1/act/Mul_output_0, %model.30.cv4.3.2.weight, %model.30.cv4.3.2.bias)\n  %/model.30/cv2.3/cv2.3.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.30/cv2.3/cv2.3.1/act/Mul_output_0, %model.30.cv2.3.2.weight, %model.30.cv2.3.2.bias)\n  %/model.30/cv3.3/cv3.3.2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.30/cv3.3/cv3.3.1/act/Mul_output_0, %model.30.cv3.3.2.weight, %model.30.cv3.3.2.bias)\n  %/model.30/Reshape_3_output_0 = Reshape[allowzero = 0](%/model.30/cv4.3/cv4.3.2/Conv_output_0, %/model.30/Constant_output_0)\n  %/model.30/Concat_4_output_0 = Concat[axis = 1](%/model.30/cv2.3/cv2.3.2/Conv_output_0, %/model.30/cv3.3/cv3.3.2/Conv_output_0)\n  %/model.30/Concat_output_0 = Concat[axis = -1](%/model.30/Reshape_output_0, %/model.30/Reshape_1_output_0, %/model.30/Reshape_2_output_0, %/model.30/Reshape_3_output_0)\n  %/model.30/Reshape_7_output_0 = Reshape[allowzero = 0](%/model.30/Concat_4_output_0, %/model.30/Constant_5_output_0)\n  %/model.30/Concat_5_output_0 = Concat[axis = 2](%/model.30/Reshape_4_output_0, %/model.30/Reshape_5_output_0, %/model.30/Reshape_6_output_0, %/model.30/Reshape_7_output_0)\n  %/model.30/Reshape_8_output_0 = Reshape[allowzero = 0](%/model.30/Concat_output_0, %/model.30/Constant_19_output_0)\n  %/model.30/Split_output_0, %/model.30/Split_output_1 = Split[axis = 1](%/model.30/Concat_5_output_0, %onnx::Split_952)\n  %/model.30/Slice_2_output_0 = Slice(%/model.30/Reshape_8_output_0, %/model.14/Constant_1_output_0, %/model.30/Constant_22_output_0, %/model.30/Constant_22_output_0, %/model.14/Constant_output_0)\n  %/model.30/Slice_3_output_0 = Slice(%/model.30/Reshape_8_output_0, %/model.30/Constant_22_output_0, %/model.30/Constant_29_output_0, %/model.30/Constant_22_output_0, %/model.14/Constant_output_0)\n  %/model.30/dfl/Reshape_output_0 = Reshape[allowzero = 0](%/model.30/Split_output_0, %/model.30/dfl/Constant_output_0)\n  %/model.30/Sigmoid_output_0 = Sigmoid(%/model.30/Split_output_1)\n  %/model.30/Mul_3_output_0 = Mul(%/model.30/Slice_2_output_0, %/model.30/Constant_24_output_0)\n  %/model.30/Sigmoid_1_output_0 = Sigmoid(%/model.30/Slice_3_output_0)\n  %/model.30/dfl/Transpose_output_0 = Transpose[perm = [0, 2, 1, 3]](%/model.30/dfl/Reshape_output_0)\n  %/model.30/Add_3_output_0 = Add(%/model.30/Mul_3_output_0, %/model.30/Constant_25_output_0)\n  %/model.30/dfl/Softmax_output_0 = Softmax[axis = 1](%/model.30/dfl/Transpose_output_0)\n  %/model.30/Mul_4_output_0 = Mul(%/model.30/Add_3_output_0, %/model.30/Constant_26_output_0)\n  %/model.30/dfl/conv/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/model.30/dfl/Softmax_output_0, %model.30.dfl.conv.weight)\n  %/model.30/Concat_7_output_0 = Concat[axis = 2](%/model.30/Mul_4_output_0, %/model.30/Sigmoid_1_output_0)\n  %/model.30/dfl/Reshape_1_output_0 = Reshape[allowzero = 0](%/model.30/dfl/conv/Conv_output_0, %/model.30/dfl/Constant_1_output_0)\n  %/model.30/Reshape_9_output_0 = Reshape[allowzero = 0](%/model.30/Concat_7_output_0, %/model.30/Constant_output_0)\n  %/model.30/Slice_output_0 = Slice(%/model.30/dfl/Reshape_1_output_0, %/model.14/Constant_1_output_0, %/model.30/Constant_22_output_0, %/model.14/Constant_output_0)\n  %/model.30/Slice_1_output_0 = Slice(%/model.30/dfl/Reshape_1_output_0, %/model.30/Constant_22_output_0, %/model.30/Mul_1_output_0, %/model.14/Constant_output_0)\n  %/model.30/Sub_output_0 = Sub(%/model.30/Constant_15_output_0, %/model.30/Slice_output_0)\n  %/model.30/Add_1_output_0 = Add(%/model.30/Constant_16_output_0, %/model.30/Slice_1_output_0)\n  %/model.30/Add_2_output_0 = Add(%/model.30/Sub_output_0, %/model.30/Add_1_output_0)\n  %/model.30/Sub_1_output_0 = Sub(%/model.30/Add_1_output_0, %/model.30/Sub_output_0)\n  %/model.30/Div_1_output_0 = Div(%/model.30/Add_2_output_0, %/model.30/Constant_24_output_0)\n  %/model.30/Concat_6_output_0 = Concat[axis = 1](%/model.30/Div_1_output_0, %/model.30/Sub_1_output_0)\n  %/model.30/Mul_2_output_0 = Mul(%/model.30/Concat_6_output_0, %/model.30/Constant_26_output_0)\n  %output0 = Concat[axis = 1](%/model.30/Mul_2_output_0, %/model.30/Sigmoid_output_0, %/model.30/Reshape_9_output_0)\n  return %output0\n}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!yolo predict pose model=Triangle_215/s_pretrain/best.onnx source=datasets/Triangle_215_Keypoint/images/triangle_4.jpg","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wget https://zihao-download.obs.cn-east-3.myhuaweicloud.com/yolov8/datasets/Triangle_215_Dataset/Triangle_215_Keypoint_coco.zip -P data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T11:39:18.814110Z","iopub.execute_input":"2025-03-27T11:39:18.814463Z","iopub.status.idle":"2025-03-27T11:39:45.522168Z","shell.execute_reply.started":"2025-03-27T11:39:18.814434Z","shell.execute_reply":"2025-03-27T11:39:45.521300Z"}},"outputs":[{"name":"stdout","text":"--2025-03-27 11:39:18--  https://zihao-download.obs.cn-east-3.myhuaweicloud.com/yolov8/datasets/Triangle_215_Dataset/Triangle_215_Keypoint_coco.zip\nResolving zihao-download.obs.cn-east-3.myhuaweicloud.com (zihao-download.obs.cn-east-3.myhuaweicloud.com)... 121.36.235.163, 121.36.235.162\nConnecting to zihao-download.obs.cn-east-3.myhuaweicloud.com (zihao-download.obs.cn-east-3.myhuaweicloud.com)|121.36.235.163|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 191452413 (183M) [application/zip]\nSaving to: â€˜data/Triangle_215_Keypoint_coco.zipâ€™\n\nTriangle_215_Keypoi 100%[===================>] 182.58M  7.52MB/s    in 25s     \n\n2025-03-27 11:39:45 (7.22 MB/s) - â€˜data/Triangle_215_Keypoint_coco.zipâ€™ saved [191452413/191452413]\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!unzip data/Triangle_215_Keypoint_coco.zip -d data >> /dev/null # è§£å‹å‹ç¼©åŒ…\n!rm -rf data/Triangle_215_Keypoint_coco.zip # åˆ é™¤å‹ç¼©åŒ…","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T11:40:57.516930Z","iopub.execute_input":"2025-03-27T11:40:57.517360Z","iopub.status.idle":"2025-03-27T11:40:59.805903Z","shell.execute_reply.started":"2025-03-27T11:40:57.517328Z","shell.execute_reply":"2025-03-27T11:40:59.804967Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!mkdir data/test_triangle","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# å•å¼ å›¾åƒ\n!yolo predict pose model=Triangle_215/m_pretrain/weights/best.onnx source=datasets/Triangle_215_Keypoint_YOLO/images/train/DSC_0219.jpg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T12:49:12.214924Z","iopub.execute_input":"2025-03-27T12:49:12.215242Z","iopub.status.idle":"2025-03-27T12:49:19.777396Z","shell.execute_reply.started":"2025-03-27T12:49:12.215214Z","shell.execute_reply":"2025-03-27T12:49:19.776445Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.97 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nLoading Triangle_215/m_pretrain/weights/best.onnx for ONNX Runtime inference...\nUsing ONNX Runtime CUDAExecutionProvider\n\u001b[0;93m2025-03-27 12:49:15.166839798 [W:onnxruntime:, transformer_memcpy.cc:83 ApplyImpl] 4 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n\nimage 1/1 /kaggle/working/datasets/Triangle_215_Keypoint_YOLO/images/train/DSC_0219.jpg: 640x640 1 sjb_rect, 24.1ms\nSpeed: 60.0ms preprocess, 24.1ms inference, 368.8ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/pose/predict\u001b[0m\nğŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"!ls datasets/Triangle_215_Keypoint_YOLO/images/train/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T12:48:57.637478Z","iopub.execute_input":"2025-03-27T12:48:57.637800Z","iopub.status.idle":"2025-03-27T12:48:57.769256Z","shell.execute_reply.started":"2025-03-27T12:48:57.637773Z","shell.execute_reply":"2025-03-27T12:48:57.768412Z"}},"outputs":[{"name":"stdout","text":"DSC_0219.jpg  DSC_0381.jpg\t       IMG_20230417_173059.jpg\nDSC_0236.jpg  DSC_0382.jpg\t       IMG_20230417_173110.jpg\nDSC_0240.jpg  DSC_0388.jpg\t       IMG_20230417_173121.jpg\nDSC_0245.jpg  DSC_0392.jpg\t       IMG_20230417_173143.jpg\nDSC_0259.jpg  DSC_0394.jpg\t       IMG_20230417_173149.jpg\nDSC_0260.jpg  DSC_0395.jpg\t       IMG_20230417_173210.jpg\nDSC_0265.jpg  DSC_0396.jpg\t       IMG_20230417_173213.jpg\nDSC_0269.jpg  DSC_0398.jpg\t       IMG_20230417_173226.jpg\nDSC_0278.jpg  DSC_0399.jpg\t       IMG_20230417_173242.jpg\nDSC_0281.jpg  DSC_0401.jpg\t       IMG_20230417_173251.jpg\nDSC_0282.jpg  DSC_0404.jpg\t       IMG_20230417_173303.jpg\nDSC_0283.jpg  DSC_0406.jpg\t       IMG_20230417_173312.jpg\nDSC_0284.jpg  DSC_0407.jpg\t       IMG_20230417_173359.jpg\nDSC_0289.jpg  DSC_0408.jpg\t       IMG_20230417_173420.jpg\nDSC_0293.jpg  DSC_0409.jpg\t       IMG_20230417_173507.jpg\nDSC_0301.jpg  DSC_0410.jpg\t       IMG_20230417_173554.jpg\nDSC_0302.jpg  DSC_0411.jpg\t       IMG_20230417_173625.jpg\nDSC_0318.jpg  DSC_0412.jpg\t       IMG_20230417_173635.jpg\nDSC_0322.jpg  DSC_0413.jpg\t       IMG_20230417_173712.jpg\nDSC_0323.jpg  DSC_0414.jpg\t       IMG_20230417_173721.jpg\nDSC_0324.jpg  DSC_0415.jpg\t       IMG_20230417_173809.jpg\nDSC_0327.jpg  DSC_0416.jpg\t       IMG_20230417_173829.jpg\nDSC_0329.jpg  DSC_0417.jpg\t       IMG_20230417_174109.jpg\nDSC_0331.jpg  DSC_0418.jpg\t       IMG_20230417_174118.jpg\nDSC_0333.jpg  DSC_0419.jpg\t       IMG_20230417_174145.jpg\nDSC_0338.jpg  DSC_0422.jpg\t       IMG_20230417_174224.jpg\nDSC_0339.jpg  DSC_0423.jpg\t       IMG_20230417_174237.jpg\nDSC_0341.jpg  IMG_20230330_201947.jpg  IMG_20230417_174252.jpg\nDSC_0342.jpg  IMG_20230417_153053.jpg  MVIMG_20230331_080908.jpg\nDSC_0343.jpg  IMG_20230417_153100.jpg  MVIMG_20230331_080912.jpg\nDSC_0345.jpg  IMG_20230417_153357.jpg  MVIMG_20230331_080914.jpg\nDSC_0346.jpg  IMG_20230417_154106.jpg  MVIMG_20230331_080915.jpg\nDSC_0347.jpg  IMG_20230417_171640.jpg  MVIMG_20230331_080920.jpg\nDSC_0348.jpg  IMG_20230417_171650.jpg  MVIMG_20230331_080943.jpg\nDSC_0351.jpg  IMG_20230417_171654.jpg  MVIMG_20230331_080944.jpg\nDSC_0352.jpg  IMG_20230417_171704.jpg  MVIMG_20230331_080948.jpg\nDSC_0353.jpg  IMG_20230417_171718.jpg  MVIMG_20230331_081009.jpg\nDSC_0354.jpg  IMG_20230417_171727.jpg  MVIMG_20230331_081021.jpg\nDSC_0356.jpg  IMG_20230417_171742.jpg  MVIMG_20230331_082231.jpg\nDSC_0358.jpg  IMG_20230417_171802.jpg  MVIMG_20230331_082232.jpg\nDSC_0359.jpg  IMG_20230417_171819.jpg  MVIMG_20230331_082251.jpg\nDSC_0360.jpg  IMG_20230417_171830.jpg  MVIMG_20230331_082301.jpg\nDSC_0361.jpg  IMG_20230417_171853.jpg  MVIMG_20230331_082325.jpg\nDSC_0362.jpg  IMG_20230417_171906.jpg  MVIMG_20230331_082329.jpg\nDSC_0363.jpg  IMG_20230417_172032.jpg  MVIMG_20230331_082333.jpg\nDSC_0364.jpg  IMG_20230417_172113.jpg  MVIMG_20230331_082339.jpg\nDSC_0365.jpg  IMG_20230417_172209.jpg  MVIMG_20230331_082341.jpg\nDSC_0366.jpg  IMG_20230417_172218.jpg  MVIMG_20230331_082419.jpg\nDSC_0367.jpg  IMG_20230417_172228.jpg  MVIMG_20230331_082420.jpg\nDSC_0368.jpg  IMG_20230417_172310.jpg  MVIMG_20230331_082425.jpg\nDSC_0370.jpg  IMG_20230417_172429.jpg  MVIMG_20230331_082428.jpg\nDSC_0371.jpg  IMG_20230417_172440.jpg  MVIMG_20230331_082431.jpg\nDSC_0372.jpg  IMG_20230417_172453.jpg  MVIMG_20230331_082433.jpg\nDSC_0373.jpg  IMG_20230417_172609.jpg  MVIMG_20230331_082443.jpg\nDSC_0375.jpg  IMG_20230417_172803.jpg  MVIMG_20230331_082445.jpg\nDSC_0376.jpg  IMG_20230417_172814.jpg  MVIMG_20230331_082447.jpg\nDSC_0379.jpg  IMG_20230417_172906.jpg\nDSC_0380.jpg  IMG_20230417_172921.jpg\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"!ls datasets/Triangle_215_Keypoint_YOLO/images/train | head  # æŸ¥çœ‹å‰10ä¸ªæ–‡ä»¶","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T12:20:57.420812Z","iopub.execute_input":"2025-03-27T12:20:57.421281Z","iopub.status.idle":"2025-03-27T12:20:57.564786Z","shell.execute_reply.started":"2025-03-27T12:20:57.421240Z","shell.execute_reply":"2025-03-27T12:20:57.563858Z"}},"outputs":[{"name":"stdout","text":"DSC_0219.jpg\nDSC_0236.jpg\nDSC_0240.jpg\nDSC_0245.jpg\nDSC_0259.jpg\nDSC_0260.jpg\nDSC_0265.jpg\nDSC_0269.jpg\nDSC_0278.jpg\nDSC_0281.jpg\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# # æŸ¥çœ‹æ–‡ä»¶å†…å®¹\n# cat Triangle_215.yaml\n\n# å¦‚æœæ–‡ä»¶è·¯å¾„ä¸åœ¨å½“å‰ç›®å½•ï¼Œéœ€è¦æŒ‡å®šå®Œæ•´è·¯å¾„ï¼Œä¾‹å¦‚ï¼š\n!cat Triangle_215/Triangle_215.yaml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T12:30:50.139139Z","iopub.execute_input":"2025-03-27T12:30:50.139498Z","iopub.status.idle":"2025-03-27T12:30:50.270549Z","shell.execute_reply.started":"2025-03-27T12:30:50.139469Z","shell.execute_reply":"2025-03-27T12:30:50.269720Z"}},"outputs":[{"name":"stdout","text":"cat: Triangle_215/Triangle_215.yaml: No such file or directory\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# å¯¼å…¥æ¨¡å‹\nfrom ultralytics import YOLO\n\nmodel = YOLO('Triangle_215/m_pretrain/weights/best.onnx', task='pose')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T12:51:47.576932Z","iopub.execute_input":"2025-03-27T12:51:47.577316Z","iopub.status.idle":"2025-03-27T12:51:48.229683Z","shell.execute_reply.started":"2025-03-27T12:51:47.577284Z","shell.execute_reply":"2025-03-27T12:51:48.229005Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# é¢„æµ‹å›¾åƒ\nresults = model.predict('data/Triangle_215_Keypoint_coco/images/DSC_0209.jpg', task='pose', save=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T13:00:25.156820Z","iopub.execute_input":"2025-03-27T13:00:25.157189Z","iopub.status.idle":"2025-03-27T13:00:25.429277Z","shell.execute_reply.started":"2025-03-27T13:00:25.157159Z","shell.execute_reply":"2025-03-27T13:00:25.428631Z"}},"outputs":[{"name":"stdout","text":"\nimage 1/1 /kaggle/working/data/Triangle_215_Keypoint_coco/images/DSC_0209.jpg: 640x640 1 sjb_rect, 27.0ms\nSpeed: 4.9ms preprocess, 27.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/pose/predict2\u001b[0m\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"!ls data/Triangle_215_Keypoint_coco/images/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T12:59:21.550555Z","iopub.execute_input":"2025-03-27T12:59:21.550882Z","iopub.status.idle":"2025-03-27T12:59:21.705762Z","shell.execute_reply.started":"2025-03-27T12:59:21.550854Z","shell.execute_reply":"2025-03-27T12:59:21.704748Z"}},"outputs":[{"name":"stdout","text":"DSC_0209.jpg  DSC_0382.jpg\t       IMG_20230417_173110.jpg\nDSC_0219.jpg  DSC_0383.jpg\t       IMG_20230417_173121.jpg\nDSC_0236.jpg  DSC_0386.jpg\t       IMG_20230417_173143.jpg\nDSC_0240.jpg  DSC_0388.jpg\t       IMG_20230417_173149.jpg\nDSC_0245.jpg  DSC_0390.jpg\t       IMG_20230417_173210.jpg\nDSC_0259.jpg  DSC_0392.jpg\t       IMG_20230417_173213.jpg\nDSC_0260.jpg  DSC_0394.jpg\t       IMG_20230417_173224.jpg\nDSC_0265.jpg  DSC_0395.jpg\t       IMG_20230417_173226.jpg\nDSC_0269.jpg  DSC_0396.jpg\t       IMG_20230417_173242.jpg\nDSC_0274.jpg  DSC_0398.jpg\t       IMG_20230417_173251.jpg\nDSC_0278.jpg  DSC_0399.jpg\t       IMG_20230417_173303.jpg\nDSC_0280.jpg  DSC_0401.jpg\t       IMG_20230417_173312.jpg\nDSC_0281.jpg  DSC_0404.jpg\t       IMG_20230417_173349.jpg\nDSC_0282.jpg  DSC_0405.jpg\t       IMG_20230417_173359.jpg\nDSC_0283.jpg  DSC_0406.jpg\t       IMG_20230417_173410.jpg\nDSC_0284.jpg  DSC_0407.jpg\t       IMG_20230417_173420.jpg\nDSC_0285.jpg  DSC_0408.jpg\t       IMG_20230417_173507.jpg\nDSC_0289.jpg  DSC_0409.jpg\t       IMG_20230417_173554.jpg\nDSC_0293.jpg  DSC_0410.jpg\t       IMG_20230417_173625.jpg\nDSC_0301.jpg  DSC_0411.jpg\t       IMG_20230417_173635.jpg\nDSC_0302.jpg  DSC_0412.jpg\t       IMG_20230417_173712.jpg\nDSC_0318.jpg  DSC_0413.jpg\t       IMG_20230417_173721.jpg\nDSC_0322.jpg  DSC_0414.jpg\t       IMG_20230417_173729.jpg\nDSC_0323.jpg  DSC_0415.jpg\t       IMG_20230417_173738.jpg\nDSC_0324.jpg  DSC_0416.jpg\t       IMG_20230417_173752.jpg\nDSC_0326.jpg  DSC_0417.jpg\t       IMG_20230417_173809.jpg\nDSC_0327.jpg  DSC_0418.jpg\t       IMG_20230417_173812.jpg\nDSC_0328.jpg  DSC_0419.jpg\t       IMG_20230417_173829.jpg\nDSC_0329.jpg  DSC_0421.jpg\t       IMG_20230417_174109.jpg\nDSC_0330.jpg  DSC_0422.jpg\t       IMG_20230417_174118.jpg\nDSC_0331.jpg  DSC_0423.jpg\t       IMG_20230417_174128.jpg\nDSC_0332.jpg  IMG_20230330_201947.jpg  IMG_20230417_174145.jpg\nDSC_0333.jpg  IMG_20230417_153053.jpg  IMG_20230417_174224.jpg\nDSC_0337.jpg  IMG_20230417_153100.jpg  IMG_20230417_174237.jpg\nDSC_0338.jpg  IMG_20230417_153357.jpg  IMG_20230417_174252.jpg\nDSC_0339.jpg  IMG_20230417_153602.jpg  MVIMG_20230331_080908.jpg\nDSC_0341.jpg  IMG_20230417_154106.jpg  MVIMG_20230331_080912.jpg\nDSC_0342.jpg  IMG_20230417_171640.jpg  MVIMG_20230331_080914.jpg\nDSC_0343.jpg  IMG_20230417_171650.jpg  MVIMG_20230331_080915.jpg\nDSC_0345.jpg  IMG_20230417_171654.jpg  MVIMG_20230331_080920.jpg\nDSC_0346.jpg  IMG_20230417_171704.jpg  MVIMG_20230331_080943.jpg\nDSC_0347.jpg  IMG_20230417_171718.jpg  MVIMG_20230331_080944.jpg\nDSC_0348.jpg  IMG_20230417_171727.jpg  MVIMG_20230331_080946.jpg\nDSC_0349.jpg  IMG_20230417_171742.jpg  MVIMG_20230331_080947.jpg\nDSC_0351.jpg  IMG_20230417_171802.jpg  MVIMG_20230331_080948.jpg\nDSC_0352.jpg  IMG_20230417_171819.jpg  MVIMG_20230331_081009.jpg\nDSC_0353.jpg  IMG_20230417_171830.jpg  MVIMG_20230331_081012.jpg\nDSC_0354.jpg  IMG_20230417_171841.jpg  MVIMG_20230331_081015.jpg\nDSC_0356.jpg  IMG_20230417_171853.jpg  MVIMG_20230331_081021.jpg\nDSC_0358.jpg  IMG_20230417_171906.jpg  MVIMG_20230331_082231.jpg\nDSC_0359.jpg  IMG_20230417_172032.jpg  MVIMG_20230331_082232.jpg\nDSC_0360.jpg  IMG_20230417_172113.jpg  MVIMG_20230331_082240.jpg\nDSC_0361.jpg  IMG_20230417_172124.jpg  MVIMG_20230331_082251.jpg\nDSC_0362.jpg  IMG_20230417_172209.jpg  MVIMG_20230331_082301.jpg\nDSC_0363.jpg  IMG_20230417_172218.jpg  MVIMG_20230331_082320.jpg\nDSC_0364.jpg  IMG_20230417_172228.jpg  MVIMG_20230331_082325.jpg\nDSC_0365.jpg  IMG_20230417_172310.jpg  MVIMG_20230331_082329.jpg\nDSC_0366.jpg  IMG_20230417_172345.jpg  MVIMG_20230331_082330.jpg\nDSC_0367.jpg  IMG_20230417_172429.jpg  MVIMG_20230331_082333.jpg\nDSC_0368.jpg  IMG_20230417_172440.jpg  MVIMG_20230331_082339.jpg\nDSC_0370.jpg  IMG_20230417_172453.jpg  MVIMG_20230331_082341.jpg\nDSC_0371.jpg  IMG_20230417_172510.jpg  MVIMG_20230331_082419.jpg\nDSC_0372.jpg  IMG_20230417_172609.jpg  MVIMG_20230331_082420.jpg\nDSC_0373.jpg  IMG_20230417_172619.jpg  MVIMG_20230331_082423.jpg\nDSC_0374.jpg  IMG_20230417_172803.jpg  MVIMG_20230331_082425.jpg\nDSC_0375.jpg  IMG_20230417_172814.jpg  MVIMG_20230331_082428.jpg\nDSC_0376.jpg  IMG_20230417_172846.jpg  MVIMG_20230331_082431.jpg\nDSC_0377.jpg  IMG_20230417_172857.jpg  MVIMG_20230331_082433.jpg\nDSC_0378.jpg  IMG_20230417_172906.jpg  MVIMG_20230331_082443.jpg\nDSC_0379.jpg  IMG_20230417_172921.jpg  MVIMG_20230331_082445.jpg\nDSC_0380.jpg  IMG_20230417_173044.jpg  MVIMG_20230331_082447.jpg\nDSC_0381.jpg  IMG_20230417_173059.jpg\n","output_type":"stream"}],"execution_count":33}]}